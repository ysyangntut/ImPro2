#include <iostream>
#include <fstream>
#include <cstdlib>
#include <cstdio>
#include <cmath>
#include <iomanip>
#include <string>
#include <vector>

#include <omp.h>

#include <opencv2/opencv.hpp>

#include "FileSeq.h"
#include "impro_util.h"

#include "matchTemplateWithRotPyr.h"

using namespace std;

// ecc_Coef = cv::findTransformECC33(
// 	imgTmplt,
// 	imgSearch,
// 	warpX3, // warp matrix (input: initial guess, output: updated)
// 	motion_type,   // motion type
// 	cv::TermCriteria(cv::TermCriteria::COUNT + cv::TermCriteria::EPS, criteriaCount, eps));


const cv::String keys =
"{help h usage ?     |      | print this message   }"
"{fileList   fList   |      | file of file list. Each row is a file name without directory, assuming files are in the same directory with the file-list file.}"
"{imgPoints  imgPts  |      | xml file of image points generated by points picker. }"
"{tmpltFile  tmplts  |      | text file of template info. Each row is motion type, template width, height, search range x, y. If EOF, the rest info is the info in the last row.}"
"{outFrmDat  oDat    |      | output result file name of each frame. Actual file name is oDat_%06d.xml}"
"{outSum     oSum    |      | output summary file name.}"
"{outCompact oCpt    |      | output compact (only x y) summary file name.}"
"{outFrame   oFrame  |      | output picture which plots boxes on each point. Actual file name is oFrame_%06d.jpg}"
"{outVideo   oVideo  |      | output video which plots boxes on each point.}"
"{showBoxes  showBx  |      | 1 for showing tracked boxes }"
"{noAsk      noAsk   |      | 1 for automatic mode, not asking any questions for optional settings }"
;

#define motion_type_tm_1   11
#define motion_type_tm_4   12
#define motion_type_tm_16  13
#define motion_type_tm_64  14
#define motion_type_tm_256 15

int FuncTrackingPyrTmpltMatch(int argc, char** argv)
{
	// Arguments
	string fnameImgPts(""); // file of image points (of each point)
	string fnameTmplts(""); // file of template info (motion type, width, height, search range x, y)
	string oDat;            // file prefix of output data of each frame (each frame a file)
	string oFrame;          // file prefix of pictures of tracked boxes 
	string oVideo;          // file of video output  
	string oSum;            // file of summary result
	string oCpt;            // file of compact (only x and y for each point) of summary result
	bool   showBx;          // boolean of showing pictures of tracked boxes 

	int nFrame, nPoint;
	FileSeq fseq;
	cv::Mat imgPoints; // nPoint * 2, 32-bit float 
	vector<int> mTypes;  // nPoint sized 
	vector<int> maxSearchSizeX;  // if  maxSearchSizeX is 50, template width is 20, the search image width is 50 + 20 + 20 = 90
	vector<int> maxSearchSizeY;  // if  maxSearchSizeY is 50, template height is 20, the search image height is 50 + 20 + 20 = 90
	vector<cv::Rect> tmpltBoxes;  // nPoint sized, including template position, width and height

	cv::VideoWriter oVideoWriter;

	cv::Mat imgInit, imgCurr, imgBoxed;

	cv::Mat bigTableTm; // Each row contains data of a frame.
	int nfFrm = 5;  // number of floats for each frame-based data
	int nfPnt = 20; // number of floats for each point-based data 
	// column 0: frame number (0-base index)
	// column 1: number of points
	// column 2: execution time (sec) to read image file
	// column 3: execution time (sec) to write frame result file 
	// column 4: execution time (sec) to write frame boxed image
	// column nfFrm +  0 + iPoint * nfPnt: template (roi) x (upper-left pixel)
	// column nfFrm +  1 + iPoint * nfPnt: template (roi) y (upper-left pixel)
	// column nfFrm +  2 + iPoint * nfPnt: template (roi) width
	// column nfFrm +  3 + iPoint * nfPnt: template (roi) height
	// column nfFrm +  4 + iPoint * nfPnt: motion type 
	// column nfFrm +  5 + iPoint * nfPnt: warp matrix w00 
	// column nfFrm +  6 + iPoint * nfPnt: warp matrix w01
	// column nfFrm +  7 + iPoint * nfPnt: warp matrix w02
	// column nfFrm +  8 + iPoint * nfPnt: warp matrix w10
	// column nfFrm +  9 + iPoint * nfPnt: warp matrix w11
	// column nfFrm + 10 + iPoint * nfPnt: warp matrix w12
	// column nfFrm + 11 + iPoint * nfPnt: warp matrix w20
	// column nfFrm + 12 + iPoint * nfPnt: warp matrix w21
	// column nfFrm + 13 + iPoint * nfPnt: Result coefficient
	// column nfFrm + 14 + iPoint * nfPnt: current image point x (pixel)
	// column nfFrm + 15 + iPoint * nfPnt: current image point y (pixel)
	// column nfFrm + 16 + iPoint * nfPnt: current image rotation (degree)
	// column nfFrm + 17 + iPoint * nfPnt: execution time (sec) for pre-processing
	// column nfFrm + 18 + iPoint * nfPnt: execution time (sec) for tracking 
	// column nfFrm + 19 + iPoint * nfPnt: execution time (sec) for post-processing

	// Get arguments
//	cv::CommandLineParser parser(argc, argv, keys);
	cv::CommandLineParser * pparser = NULL;
	if (argc >= 1) {
		pparser = new cv::CommandLineParser(argc, argv, keys);
	}

	if (pparser)
		if ((*pparser).has("help") || argc <= 1) {
			(*pparser).printMessage();
			std::cout << "\nUsage: \n";
			std::cout << "For example: TrackPointsPyrTmpltMatch -fList=fList.txt -imgPts=imgPts.xml -motType=mType.txt -tmpSize=tmpltSize.txt \n";
		}

	// define list of picture files
	if (pparser)
		fseq.setFilesByListFile((*pparser).get<string>("fList"));
	if (fseq.num_files() == 0) {
		fseq.setDirFilesByConsole();
		if (fseq.num_files() <= 0) {
			std::cout << "User cancelled.\n"; std::cout.flush();
			return -1;
		}
	}
	printf("There are %d files. From %s to %s.\n", fseq.num_files(), fseq.fullPathOfFile(0).c_str(),
		fseq.fullPathOfFile(fseq.num_files() - 1).c_str());
	nFrame = fseq.num_files();

	// file name of image points ('g' for gui) --> fnameImgPts 
	fnameImgPts = string("");
	if (pparser)
		fnameImgPts = (*pparser).get<string>("imgPts");
	if (fnameImgPts.length() <= 0) {
		std::cout << "Enter xml file of image points (vector of Point2f, vector of rect, vector of motion type, generated by template picking) ('g' for gui dialog): ";
		fnameImgPts = readStringLineFromCin();
		if (fnameImgPts.length() == 1 && fnameImgPts[0] == 'g')
			fnameImgPts = uigetfile();
		if (fnameImgPts.length() == 0) {
			std::cout << "User cancelled.\n";
			return -1;
		}
	}
	// read image points
	cv::FileStorage fsImgPts(fnameImgPts, cv::FileStorage::READ);
	if (fsImgPts.isOpened() == false)
	{
		cerr << "Cannot open image point file " << fnameImgPts << endl;
		return -1;
	}
	vector<cv::Point2f> vecP2f;
	fsImgPts["VecPoint2f"] >> vecP2f;
	nPoint = (int)vecP2f.size();
	imgPoints = cv::Mat::zeros(nPoint, 2, CV_32F);
	for (int i = 0; i < nPoint; i++) {
		imgPoints.at<float>(i, 0) = vecP2f[i].x;
		imgPoints.at<float>(i, 1) = vecP2f[i].y;
	}
	printf("Image point %d: %6.1f %6.1f \n", 0, imgPoints.at<float>(0, 0), imgPoints.at<float>(0, 1));
	printf("Image point %d: %6.1f %6.1f \n", nPoint - 1, imgPoints.at<float>(nPoint - 1, 0), imgPoints.at<float>(nPoint - 1, 1));
	// template range (rect) 
	fsImgPts["VecRect"] >> tmpltBoxes;
	fsImgPts["VecMotionType"] >> mTypes;
	fsImgPts["VecSearchSizeX"] >> maxSearchSizeX;
	fsImgPts["VecSearchSizeY"] >> maxSearchSizeY;
	fsImgPts.release();

	// file name of output frame result ('g' for gui) --> oDat 
	if (pparser)
		oDat = (*pparser).get<string>("oDat");
	else
		oDat = string("");
	if (oDat.length() <= 0) {
		std::cout << "Enter file prefix of frame result (\"XXX\" for XXX_%06d.xml', 'g' for ui file dialog.): ";
		while (true) {
			oDat = readStringLineFromCin();
			if (oDat[0] == '#') continue;
			break;
		}
		if (oDat.length() == 1 && oDat[0] == 'g')
			oDat = uiputfile();
		if (oDat.length() == 0) {
			std::cout << "User chose to skip frame result.\n";
		}
	}

	// file name of output frame picture ('g' for gui) --> oFrame 
	if (pparser)
		oFrame = (*pparser).get<string>("oFrame");
	else
		oFrame = string("");
	if (oFrame.length() <= 0) {
		std::cout << "Enter file prefix of frame picture (\"XXX\" for XXX_%06d.JPG', single-char for not outputing, 'g' for ui file dialog.): ";
		oFrame = readStringLineFromCin();
		if (oFrame.length() == 1 && oFrame[0] == 'g')
			oFrame = uiputfile();
		if (oFrame.length() == 0 || (oFrame.length() == 1 && oFrame[0] == 'n')) {
			std::cout << "User chose to skip frame picture.\n";
			oFrame = string("");
		}
	}

	// file name of output video ('g' for gui) --> oVideo 
	if (pparser)
		oVideo = (*pparser).get<string>("oVideo");
	else
		oVideo = string("");
	if (oVideo.length() <= 0) {
		std::cout << "Enter output video file name, single-char for not outputing, 'g' for ui file dialog.): ";
		oVideo = readStringLineFromCin();
		if (oVideo.length() == 1 && oVideo[0] == 'g')
			oVideo = uiputfile();
		if (oVideo.length() <= 1) {
			std::cout << "User chose to skip video output.\n";
			oVideo = string("");
		}
	}

	// file name of output summary ('g' for gui) --> oSum 
	if (pparser)
		oSum = (*pparser).get<string>("oSum");
	else
		oSum = string("");
	if (oSum.length() <= 0) {
		std::cout << "Enter file of summary result ('g' for ui file dialog.): ";
		oSum = readStringLineFromCin();
		if (oSum.length() == 1 && oSum[0] == 'g')
			oSum = uiputfile();
		if (oSum.length() == 0) {
			std::cout << "User chose to skip summary file.\n";
		}
	}

	if (pparser)
		oCpt = (*pparser).get<string>("oCpt");
	else
		oCpt = string("");
	if (oCpt.length() <= 0) {
		std::cout << "Enter file of compact summary result (only image x y for each point)  ('g' for ui file dialog.): ";
		oCpt = readStringLineFromCin();
		if (oCpt.length() == 1 && oCpt[0] == 'g')
			oCpt = uiputfile();
		if (oCpt.length() == 0) {
			std::cout << "User chose to skip summary file.\n";
		}
	}

	// show boxes of tracked points --> showBx  
	std::string showBxStr = string("");
	if (pparser)
		showBxStr = (*pparser).get<string>("showBx");
	if (showBxStr.length() <= 0) {
		std::cout << "Show pictures of tracked points? (1 for true): ";
		showBxStr = readStringLineFromCin();
		if (showBxStr.length() >= 1 && showBxStr[0] == '1')
			showBx = true;
		else
			showBx = false;
	}

	printf("Motion type of point %d is %d \n", 0, mTypes[0]);
	printf("Motion type of point %d is %d \n", nPoint - 1, mTypes[nPoint - 1]);
	printf("Tmplt size of point %d is %d %d\n", 0, tmpltBoxes[0].width, tmpltBoxes[0].height);
	printf("Tmplt size of point %d is %d %d\n", nPoint - 1, tmpltBoxes[nPoint - 1].width, tmpltBoxes[nPoint - 1].height);

	// initialize big table  
	bigTableTm = cv::Mat::zeros(nFrame, nfFrm + nfPnt * nPoint, CV_32F);

	// Frame 0 operations
	int iFrame = 0;
	double t_imreadFrm0 = (double)cv::getTickCount();
	imgInit = cv::imread(fseq.fullPathOfFile(iFrame), cv::IMREAD_GRAYSCALE);
	if (imgInit.cols <= 0 || imgInit.rows <= 0) {
		cerr << "Cannot read image " << iFrame << ": " << fseq.fullPathOfFile(iFrame) << ".\n";
		cerr.flush();
		return -1;
	}
	t_imreadFrm0 = ((double)cv::getTickCount() - t_imreadFrm0) / cv::getTickFrequency();
	bigTableTm.at<float>(iFrame, 0) = (float)iFrame;
	bigTableTm.at<float>(iFrame, 1) = (float)nPoint;
	bigTableTm.at<float>(iFrame, 2) = (float)t_imreadFrm0; // execution time (sec) to read image file
	bigTableTm.at<float>(iFrame, 3) = (float) 0.f; //	execution time (sec) to write frame result file 
	bigTableTm.at<float>(iFrame, 4) = (float) 0.f; //	execution time (sec) to write frame boxed image
	for (int iPoint = 0; iPoint < nPoint; iPoint++)
	{
		cv::Point2f ref;
//		tmpltBoxes[iPoint] = getTmpltRectFromImage(imgInit,
//			cv::Point2f(imgPoints.at<float>(iPoint, 0), imgPoints.at<float>(iPoint, 1)),
//			cv::Size(tmpltBoxes[iPoint].width, tmpltBoxes[iPoint].height),
//			ref);
		bigTableTm.at<float>(iFrame, nfFrm + 0 + iPoint * nfPnt) = (float)tmpltBoxes[iPoint].x;      // Will not change with iFrame
		bigTableTm.at<float>(iFrame, nfFrm + 1 + iPoint * nfPnt) = (float)tmpltBoxes[iPoint].y;		 // Will not change with iFrame
		bigTableTm.at<float>(iFrame, nfFrm + 2 + iPoint * nfPnt) = (float)tmpltBoxes[iPoint].width;	 // Will not change with iFrame
		bigTableTm.at<float>(iFrame, nfFrm + 3 + iPoint * nfPnt) = (float)tmpltBoxes[iPoint].height; // Will not change with iFrame
		bigTableTm.at<float>(iFrame, nfFrm + 4 + iPoint * nfPnt) = (float)mTypes[iPoint];            // Will not change with iFrame
		bigTableTm.at<float>(iFrame, nfFrm + 5 + iPoint * nfPnt) = 1.0f;
		bigTableTm.at<float>(iFrame, nfFrm + 6 + iPoint * nfPnt) = 0.0f;
		bigTableTm.at<float>(iFrame, nfFrm + 7 + iPoint * nfPnt) = (float)tmpltBoxes[iPoint].x;
		bigTableTm.at<float>(iFrame, nfFrm + 8 + iPoint * nfPnt) = 0.0f;
		bigTableTm.at<float>(iFrame, nfFrm + 9 + iPoint * nfPnt) = 1.0f;
		bigTableTm.at<float>(iFrame, nfFrm + 10 + iPoint * nfPnt) = (float)tmpltBoxes[iPoint].y;
		bigTableTm.at<float>(iFrame, nfFrm + 11 + iPoint * nfPnt) = 0.0f;
		bigTableTm.at<float>(iFrame, nfFrm + 12 + iPoint * nfPnt) = 0.0f;
		bigTableTm.at<float>(iFrame, nfFrm + 13 + iPoint * nfPnt) = 1.0f;
		bigTableTm.at<float>(iFrame, nfFrm + 14 + iPoint * nfPnt) = imgPoints.at<float>(iPoint, 0);
		bigTableTm.at<float>(iFrame, nfFrm + 15 + iPoint * nfPnt) = imgPoints.at<float>(iPoint, 1);
		bigTableTm.at<float>(iFrame, nfFrm + 16 + iPoint * nfPnt) = 0.0f;
		bigTableTm.at<float>(iFrame, nfFrm + 17 + iPoint * nfPnt) = 0.0f;	// execution time (sec) for pre-processing
		bigTableTm.at<float>(iFrame, nfFrm + 18 + iPoint * nfPnt) = 0.0f;	// execution time (sec) for tracking 
		bigTableTm.at<float>(iFrame, nfFrm + 19 + iPoint * nfPnt) = 0.0f;	// execution time (sec) for post-processing
	}

	// Main loop. 
	float coef_threshold = 0.95f;
	int64 tickCountStart = cv::getTickCount();
	for (int iFrame = 1; iFrame < nFrame; iFrame++)
	{
		// read image
		double t_imreadFrm = (double)cv::getTickCount();
		fseq.waitForFile(iFrame);
		imgBoxed = cv::imread(fseq.fullPathOfFile(iFrame), cv::IMREAD_COLOR);
		cv::cvtColor(imgBoxed, imgCurr, cv::COLOR_BGR2GRAY);
		if (imgCurr.cols <= 0 || imgCurr.rows <= 0) {
			cerr << "Cannot read image " << iFrame << ": " << fseq.fullPathOfFile(iFrame) << ".\n";
			cerr.flush();
			return -1;
		}
		t_imreadFrm = ((double)cv::getTickCount() - t_imreadFrm) / cv::getTickFrequency();

		bigTableTm.at<float>(iFrame, 0) = (float)iFrame;
		bigTableTm.at<float>(iFrame, 1) = (float)nPoint;
		bigTableTm.at<float>(iFrame, 2) = (float)t_imreadFrm0; // execution time (sec) to read image file
		bigTableTm.at<float>(iFrame, 3) = (float) 0.f; //	execution time (sec) to write frame result file 
		bigTableTm.at<float>(iFrame, 4) = (float) 0.f; //	execution time (sec) to write frame boxed image

// If OpenMP is disabled, probably it is because tracking computing time is relatively small, openMP is not helping significantly but increasing threading load.
//#pragma omp parallel for
		for (int iPoint = 0; iPoint < nPoint; iPoint++)
		{
			// timing pre-processing
			double t_point_pre = (double)cv::getTickCount();

			// template
			bigTableTm.at<float>(iFrame, nfFrm + 0 + iPoint * nfPnt) = (float)tmpltBoxes[iPoint].x;      // Will not change with iFrame
			bigTableTm.at<float>(iFrame, nfFrm + 1 + iPoint * nfPnt) = (float)tmpltBoxes[iPoint].y;		// Will not change with iFrame
			bigTableTm.at<float>(iFrame, nfFrm + 2 + iPoint * nfPnt) = (float)tmpltBoxes[iPoint].width;	// Will not change with iFrame
			bigTableTm.at<float>(iFrame, nfFrm + 3 + iPoint * nfPnt) = (float)tmpltBoxes[iPoint].height; // Will not change with iFrame

			// motion type 
			bigTableTm.at<float>(iFrame, nfFrm + 4 + iPoint * nfPnt) = (float)mTypes[iPoint];

			// initial guess of warp
			cv::Mat warp = cv::Mat::eye(3, 3, CV_32F);

			// initial guess of disp/rot is the previous data (find closest frame that coefficient > coef_threshold)
			int iFramePreviousValid = 0; // for iStep == 0, iFramePreviousValid is 0. 
			for (iFramePreviousValid = iFrame - 1; iFramePreviousValid > 0; iFramePreviousValid--) {
				if (bigTableTm.at<float>(iFrame - 1, nfFrm + 13 + iPoint * nfPnt) >= coef_threshold)
					break;
			}
			//warp.at<float>(0, 0) = bigTableTm.at<float>(iFramePreviousValid, nfFrm + 5 + iPoint * nfPnt);
			//warp.at<float>(0, 1) = bigTableTm.at<float>(iFramePreviousValid, nfFrm + 6 + iPoint * nfPnt);
			//warp.at<float>(0, 2) = bigTableTm.at<float>(iFramePreviousValid, nfFrm + 7 + iPoint * nfPnt);
			//warp.at<float>(1, 0) = bigTableTm.at<float>(iFramePreviousValid, nfFrm + 8 + iPoint * nfPnt);
			//warp.at<float>(1, 1) = bigTableTm.at<float>(iFramePreviousValid, nfFrm + 9 + iPoint * nfPnt);
			//warp.at<float>(1, 2) = bigTableTm.at<float>(iFramePreviousValid, nfFrm + 10 + iPoint * nfPnt);
			//warp.at<float>(2, 0) = bigTableTm.at<float>(iFramePreviousValid, nfFrm + 11 + iPoint * nfPnt);
			//warp.at<float>(2, 1) = bigTableTm.at<float>(iFramePreviousValid, nfFrm + 12 + iPoint * nfPnt);
			//warp.at<float>(2, 2) = 1.0f;
			double est_x = bigTableTm.at<float>(iFramePreviousValid, nfFrm + 14 + iPoint * nfPnt); // estimated position x
			double est_y = bigTableTm.at<float>(iFramePreviousValid, nfFrm + 15 + iPoint * nfPnt); // estimated position y
			double est_r = bigTableTm.at<float>(iFramePreviousValid, nfFrm + 16 + iPoint * nfPnt); // estimated position

			// timing pre-processing
			t_point_pre = ((double)cv::getTickCount() - t_point_pre) / cv::getTickFrequency();

			//			cv::imshow("TMPLT", imgInit(tmpltBoxes[iPoint])); 
			//			cv::waitKey(0); 
			//			cv::destroyWindow("TMPLT"); 
			//			std::cout << "Motion type: " << bigTableTm.at<float>(iFrame, nfFrm +  4 + iPoint * nfPnt) << endl;
			//			cout.flush(); 

			// timing tracking
			double t_point_tracking = (double)cv::getTickCount();

			// Tracking 
			int motion_type = (int)bigTableTm.at<float>(iFrame, nfFrm + 4 + iPoint * nfPnt);
			double coef;

			double ref_x = imgPoints.at<float>(iPoint, 0) - (float)tmpltBoxes[iPoint].x;
			double ref_y = imgPoints.at<float>(iPoint, 1) - (float)tmpltBoxes[iPoint].y;
			double min_x = -1.0 * maxSearchSizeX[iPoint] + est_x; 
			double max_x = +1.0 * maxSearchSizeX[iPoint] + est_x;
			double min_y = -1.0 * maxSearchSizeY[iPoint] + est_y;
			double max_y = +1.0 * maxSearchSizeY[iPoint] + est_y;
			double min_r = 0.0; 
			double max_r = 0.0; 
			double prc_x, prc_y, prc_r = 1.0; 
			if (motion_type == motion_type_tm_1) {
				prc_x = prc_y = 1.0;
			} else if (motion_type == motion_type_tm_4) {
				prc_x = prc_y = 1./4.; // .25
			} else if (motion_type == motion_type_tm_16) {
				prc_x = prc_y = 1. / 16.; // .0625
			} else if (motion_type == motion_type_tm_64) {
				prc_x = prc_y = 1. / 64.; // 0.015625
			} else if (motion_type == motion_type_tm_256) {
				prc_x = prc_y = 1. / 256.; // 0.0039
			} else {
//				prc_x = prc_y = 1. / 16.; // .0625
				prc_x = prc_y = 1. / 8.; // .125
			}
			vector<double> tmRes(8, 0.0); 

//			try {
			int cloneImagesBeforeTracking = 0;
			if (cloneImagesBeforeTracking == 0) {
				matchTemplateWithRotPyr(
					imgCurr,
					imgInit(tmpltBoxes[iPoint]),
					ref_x, ref_y,
					min_x, max_x, prc_x,
					min_y, max_y, prc_y,
					min_r, max_r, prc_r,
					tmRes);
			}
			else if (cloneImagesBeforeTracking == 1) {
				// copy to smaller clone images
				int maxMoveX = maxSearchSizeX[iPoint];
				int maxMoveY = maxSearchSizeY[iPoint];
				cv::Point2f refPoint;
				cv::Mat imgTmplt, imgSearch;
				imgInit(tmpltBoxes[iPoint]).copyTo(imgTmplt);
				cv::Rect rectSearch =
					getTmpltRectFromImage(imgCurr, cv::Point2f((float)est_x, (float)est_y),
						cv::Size(imgTmplt.cols + 2 * maxMoveX, imgTmplt.rows + 2 * maxMoveY), refPoint);
				imgCurr(rectSearch).copyTo(imgSearch);
				matchTemplateWithRotPyr(
					imgSearch,
					imgTmplt,
					ref_x, ref_y,
					min_x - rectSearch.x, max_x - rectSearch.x, prc_x,
					min_y - rectSearch.y, max_y - rectSearch.y, prc_y,
					min_r, max_r, prc_r,
					tmRes);
				tmRes[0] += rectSearch.x; 
				tmRes[1] += rectSearch.y;
			}
//			}
//			catch (...) {
				// If matching fails, use previous frame result with coefficiet = 0.0f
				//warp.at<float>(0, 0) = bigTableTm.at<float>(iFrame - 1, nfFrm + 5 + iPoint * nfPnt);
				//warp.at<float>(0, 1) = bigTableTm.at<float>(iFrame - 1, nfFrm + 6 + iPoint * nfPnt);
				//warp.at<float>(0, 2) = bigTableTm.at<float>(iFrame - 1, nfFrm + 7 + iPoint * nfPnt);
				//warp.at<float>(1, 0) = bigTableTm.at<float>(iFrame - 1, nfFrm + 8 + iPoint * nfPnt);
				//warp.at<float>(1, 1) = bigTableTm.at<float>(iFrame - 1, nfFrm + 9 + iPoint * nfPnt);
				//warp.at<float>(1, 2) = bigTableTm.at<float>(iFrame - 1, nfFrm + 10 + iPoint * nfPnt);
				//warp.at<float>(2, 0) = bigTableTm.at<float>(iFrame - 1, nfFrm + 11 + iPoint * nfPnt);
				//warp.at<float>(2, 1);  bigTableTm.at<float>(iFrame - 1, nfFrm + 12 + iPoint * nfPnt);
//			}

			t_point_tracking = ((double)cv::getTickCount() - t_point_tracking) / cv::getTickFrequency();

			//				std::cout << "Warp after: \n" << warp << endl;
			//				cout.flush(); 
			//				system("pause"); 

						// timing post-processing
			double t_point_post = (double)cv::getTickCount();

			// convert to equivalent warp matrix (according to x,y,rot, i.e., tmRes[0],[1].[2])
			cv::Point2f center((float)ref_x, (float)ref_y);
			cv::Mat warpX3 = cv::getRotationMatrix2D(center, tmRes[2], 1.0);
			warpX3.convertTo(warpX3, CV_32F); 
			warpX3.at<float>(0,2) += (float) (tmRes[0] - ref_x);
			warpX3.at<float>(1,2) += (float) (tmRes[1] - ref_y);
			warpX3.copyTo(warp(cv::Rect(0, 0, 3, 2))); 
			coef = tmRes[3]; 

//			cout << "Point " << iPoint << endl;
//			cout << "  warp: \n" << warp << endl;
			// Update result to big table
			bigTableTm.at<float>(iFrame, nfFrm + 5 + iPoint * nfPnt) = warp.at<float>(0, 0);
			bigTableTm.at<float>(iFrame, nfFrm + 6 + iPoint * nfPnt) = warp.at<float>(0, 1);
			bigTableTm.at<float>(iFrame, nfFrm + 7 + iPoint * nfPnt) = warp.at<float>(0, 2);
			bigTableTm.at<float>(iFrame, nfFrm + 8 + iPoint * nfPnt) = warp.at<float>(1, 0);
			bigTableTm.at<float>(iFrame, nfFrm + 9 + iPoint * nfPnt) = warp.at<float>(1, 1);
			bigTableTm.at<float>(iFrame, nfFrm + 10 + iPoint * nfPnt) = warp.at<float>(1, 2);
			bigTableTm.at<float>(iFrame, nfFrm + 11 + iPoint * nfPnt) = warp.at<float>(2, 0);
			bigTableTm.at<float>(iFrame, nfFrm + 12 + iPoint * nfPnt) = warp.at<float>(2, 1);
			bigTableTm.at<float>(iFrame, nfFrm + 13 + iPoint * nfPnt) = (float)coef;

			// Find current image point 
			bigTableTm.at<float>(iFrame, nfFrm + 14 + iPoint * nfPnt) = (float) tmRes[0];
			bigTableTm.at<float>(iFrame, nfFrm + 15 + iPoint * nfPnt) = (float) tmRes[1];

			// Find rotation 
			bigTableTm.at<float>(iFrame, nfFrm + 16 + iPoint * nfPnt) = (float) tmRes[2];
			
			t_point_post = ((double)cv::getTickCount() - t_point_post) / cv::getTickFrequency();

			bigTableTm.at<float>(iFrame, nfFrm + 17 + iPoint * nfPnt) = (float)t_point_pre;      // execution time (sec) for pre-processing 
			bigTableTm.at<float>(iFrame, nfFrm + 18 + iPoint * nfPnt) = (float)t_point_tracking; // execution time (sec) for tracking 
			bigTableTm.at<float>(iFrame, nfFrm + 19 + iPoint * nfPnt) = (float)t_point_post;     // execution time (sec) for post-processing

		} // next point

		// print marked boxes picture of each frame
		double t_writeImg = (double)cv::getTickCount();
		if (oFrame.length() > 0 || showBx == true || oVideo.length() > 0) {
			// plot boxes on imgBoxed
			for (int iPoint = 0; iPoint < nPoint; iPoint++) {
				// get warp matrix of iPoint of iFrame
				cv::Mat warp(3, 3, CV_32F);
				warp.at<float>(0, 0) = bigTableTm.at<float>(iFrame, nfFrm + 5 + iPoint * nfPnt);
				warp.at<float>(0, 1) = bigTableTm.at<float>(iFrame, nfFrm + 6 + iPoint * nfPnt);
				warp.at<float>(0, 2) = bigTableTm.at<float>(iFrame, nfFrm + 7 + iPoint * nfPnt);
				warp.at<float>(1, 0) = bigTableTm.at<float>(iFrame, nfFrm + 8 + iPoint * nfPnt);
				warp.at<float>(1, 1) = bigTableTm.at<float>(iFrame, nfFrm + 9 + iPoint * nfPnt);
				warp.at<float>(1, 2) = bigTableTm.at<float>(iFrame, nfFrm + 10 + iPoint * nfPnt);
				warp.at<float>(2, 0) = bigTableTm.at<float>(iFrame, nfFrm + 11 + iPoint * nfPnt);
				warp.at<float>(2, 1) = bigTableTm.at<float>(iFrame, nfFrm + 12 + iPoint * nfPnt);
				warp.at<float>(2, 2) = 1.0f;
				// define un-warp box
				cv::Mat p4m(3, 5, CV_32F);
				p4m.at<float>(0, 0) = 0.f;
				p4m.at<float>(1, 0) = 0.f;
				p4m.at<float>(2, 0) = 1.f;
				p4m.at<float>(0, 1) = 0.f;
				p4m.at<float>(1, 1) = bigTableTm.at<float>(iFrame, nfFrm + 3 + iPoint * nfPnt); // h
				p4m.at<float>(2, 1) = 1.f;
				p4m.at<float>(0, 2) = bigTableTm.at<float>(iFrame, nfFrm + 2 + iPoint * nfPnt); // w
				p4m.at<float>(1, 2) = bigTableTm.at<float>(iFrame, nfFrm + 3 + iPoint * nfPnt); // h
				p4m.at<float>(2, 2) = 1.f;
				p4m.at<float>(0, 3) = bigTableTm.at<float>(iFrame, nfFrm + 2 + iPoint * nfPnt); // w
				p4m.at<float>(1, 3) = 0.f;
				p4m.at<float>(2, 3) = 1.f;
				p4m.at<float>(0, 4) = imgPoints.at<float>(iPoint, 0) - (float)tmpltBoxes[iPoint].x;
				p4m.at<float>(1, 4) = imgPoints.at<float>(iPoint, 1) - (float)tmpltBoxes[iPoint].y;
				p4m.at<float>(2, 4) = 1.f;
				// calculate warpped box
				p4m = warp * p4m;
				p4m.at<float>(0, 0) /= p4m.at<float>(2, 0);
				p4m.at<float>(0, 1) /= p4m.at<float>(2, 1);
				p4m.at<float>(0, 2) /= p4m.at<float>(2, 2);
				p4m.at<float>(0, 3) /= p4m.at<float>(2, 3);
				p4m.at<float>(0, 4) /= p4m.at<float>(2, 4);
				p4m.at<float>(1, 0) /= p4m.at<float>(2, 0);
				p4m.at<float>(1, 1) /= p4m.at<float>(2, 1);
				p4m.at<float>(1, 2) /= p4m.at<float>(2, 2);
				p4m.at<float>(1, 3) /= p4m.at<float>(2, 3);
				p4m.at<float>(1, 4) /= p4m.at<float>(2, 4);
				// plot box 
				int shift = 3, shFact = 1 << shift;
				cv::Point p0 = cv::Point((int)(p4m.at<float>(0, 0) * shFact + .5), (int)(p4m.at<float>(1, 0) * shFact + .5));
				cv::Point p1 = cv::Point((int)(p4m.at<float>(0, 1) * shFact + .5), (int)(p4m.at<float>(1, 1) * shFact + .5));
				cv::Point p2 = cv::Point((int)(p4m.at<float>(0, 2) * shFact + .5), (int)(p4m.at<float>(1, 2) * shFact + .5));
				cv::Point p3 = cv::Point((int)(p4m.at<float>(0, 3) * shFact + .5), (int)(p4m.at<float>(1, 3) * shFact + .5));
				cv::Point p4 = cv::Point((int)(p4m.at<float>(0, 4) * shFact + .5), (int)(p4m.at<float>(1, 4) * shFact + .5));
				int thickness = 2;
				int linetype = cv::LINE_AA;
				if (bigTableTm.at<float>(iFrame, nfFrm + 13 + iPoint * nfPnt) <= 0.0f)
					thickness = 1;
				cv::line(imgBoxed, p0, p1, cv::Scalar(127, 255, 127), thickness, linetype, shift);
				cv::line(imgBoxed, p1, p2, cv::Scalar(127, 255, 127), thickness, linetype, shift);
				cv::line(imgBoxed, p2, p3, cv::Scalar(127, 255, 127), thickness, linetype, shift);
				cv::line(imgBoxed, p3, p0, cv::Scalar(127, 255, 127), thickness, linetype, shift);
				if (bigTableTm.at<float>(iFrame, nfFrm + 13 + iPoint * nfPnt) > coef_threshold) {
					cv::line(imgBoxed, p0, p4, cv::Scalar(127, 255, 127), 1, linetype, shift);
					cv::line(imgBoxed, p1, p4, cv::Scalar(127, 255, 127), 1, linetype, shift);
					cv::line(imgBoxed, p2, p4, cv::Scalar(127, 255, 127), 1, linetype, shift);
					cv::line(imgBoxed, p3, p4, cv::Scalar(127, 255, 127), 1, linetype, shift);
				}

			} // end of point loop

			if (oFrame.length() > 1) {
				char ofsFrame[1000];
                snprintf(ofsFrame, 1000, "_%06d.jpg", iFrame);
				std::string ofsFrameStr = oFrame + std::string(ofsFrame);
				cv::imwrite(ofsFrameStr, imgBoxed);
			}
			if (oVideo.length() > 1 && iFrame <= 1) {
				int f4cc = preferredFourcc();
				oVideoWriter.open(oVideo, f4cc, 30.0, imgBoxed.size());
			}
			if (oVideo.length() > 0 && oVideo[0] != 'n' && oVideoWriter.isOpened())
				oVideoWriter << imgBoxed;

			// show boxes 
			if (showBx == true) {
				cv::Mat imgShow;
				int maxW = 1280, maxH = 720;
				float facH = maxH * 1.0f / imgBoxed.rows;
				float facW = maxW * 1.0f / imgBoxed.cols;
				float fac = facH > facW ? facW : facH;
				cv::resize(imgBoxed, imgShow, cv::Size(0, 0), fac, fac, cv::INTER_LANCZOS4);
				cv::imshow("Tracked points", imgShow);
				cv::waitKey(1);
			}
		} // end if output box plot
		t_writeImg = ((double)cv::getTickCount() - t_writeImg) / cv::getTickFrequency();
		bigTableTm.at<float>(iFrame, 4) = (float)t_writeImg; //	execution time (sec) to write frame boxed image

		// print result of this frame to a file
		double t_writeTxt = (double)cv::getTickCount();
		if (oDat.length() > 0) {
			// txt file
			char ofsFname[1000];
            snprintf(ofsFname, 1000, "_%06d.txt", iFrame);
			std::string ofsFnameStr = oDat + std::string(ofsFname);
			FILE * ofile;
			fopen_s(&ofile, ofsFnameStr.c_str(), "w");
			fprintf(ofile, "  Frame NumPts       T_ReadImg      T_WriteTxt      T_WriteImg");
			for (int iPoint = 0; iPoint < nPoint; iPoint++) {
				fprintf(ofile, " X0_%03d Y0_%03d  W_%03d  H_%03d MT_%03d         W00_%03d         W01_%03d         W02_%03d         W10_%03d         W11_%03d         W12_%03d         W20_%03d         W21_%03d         Ecf_%03d         Xcr_%03d         Ycr_%03d         Rot_%03d        Tpre_%03d      Ttrack_%03d       Tpost_%03d",
					iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint);
			}
			fprintf(ofile, "\n");
			fprintf(ofile, " %6d %6d", iFrame, nPoint);
			for (int i = 2; i < nfFrm; i++)
				fprintf(ofile, " %15.7f", bigTableTm.at<float>(iFrame, i));
			for (int iPoint = 0; iPoint < nPoint; iPoint++) {
				for (int i = 0 + nfFrm + iPoint * nfPnt; i <= 4 + nfFrm + iPoint * nfPnt; i++)
					fprintf(ofile, " %6d", (int)(bigTableTm.at<float>(iFrame, i) + .5f));
				for (int i = 5 + nfFrm + iPoint * nfPnt; i < nfFrm + (iPoint + 1) * nfPnt; i++)
					fprintf(ofile, " %15.7e", bigTableTm.at<float>(iFrame, i));
			}
			fprintf(ofile, "\n");
			std::fclose(ofile);
			// xml file
			vector<cv::Point2f> trackedImgPoints(nPoint);
			for (int iPoint = 0; iPoint < nPoint; iPoint++) {
				trackedImgPoints[iPoint].x = bigTableTm.at<float>(iFrame, nfFrm + 14 + iPoint * nfPnt);
				trackedImgPoints[iPoint].y = bigTableTm.at<float>(iFrame, nfFrm + 15 + iPoint * nfPnt);
			}
            snprintf(ofsFname, 1000, "_%06d.xml", iFrame);
			cv::FileStorage ofsFileTrackedImgPoints(oDat + ofsFname, cv::FileStorage::WRITE);
			ofsFileTrackedImgPoints << "VecPoint2f" << trackedImgPoints;
			ofsFileTrackedImgPoints.release();
		} // end of output frame result
		t_writeTxt = ((double)cv::getTickCount() - t_writeTxt) / cv::getTickFrequency();
		bigTableTm.at<float>(iFrame, 3) = (float)t_writeTxt; //	execution time (sec) to write frame result file 

		if (iFrame % 2 == 0) {
			std::cout << "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
				"\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b";
			int64 tickCountFrameEnd = cv::getTickCount();
			float timePast = (float)((tickCountFrameEnd - tickCountStart) / cv::getTickFrequency());
			float timeTotalEstimated = timePast / ((iFrame + 1) * 1.0f / nFrame);
			float timeReamining = timeTotalEstimated - timePast;
			printf("Frame %06d/%06d. %6d points/sec. Time remaining: %6d sec.", iFrame, nFrame,
				(int)(nPoint * (iFrame + 1) / timePast), (int)(timeReamining + .5f));
		}

	} // next frame 

	// print result of all frames to a summary file
	if (oSum.length() > 0) {
		FILE * ofile;
		fopen_s(&ofile, oSum.c_str(), "w");
		fprintf(ofile, "  Frame NumPts       T_ReadImg      T_WriteTxt      T_WriteImg");
		for (int iPoint = 0; iPoint < nPoint; iPoint++) {
			fprintf(ofile, " X0_%03d Y0_%03d  W_%03d  H_%03d MT_%03d         W00_%03d         W01_%03d         W02_%03d         W10_%03d         W11_%03d         W12_%03d         W20_%03d         W21_%03d         Ecf_%03d         Xcr_%03d         Ycr_%03d         Rot_%03d        Tpre_%03d      Ttrack_%03d       Tpost_%03d",
				iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint);
		}
		fprintf(ofile, "\n");
		for (int iFrame = 0; iFrame < nFrame; iFrame++) {
			fprintf(ofile, " %6d %6d", iFrame, nPoint);
			for (int i = 2; i < nfFrm; i++)
				fprintf(ofile, " %15.7f", bigTableTm.at<float>(iFrame, i));
			for (int iPoint = 0; iPoint < nPoint; iPoint++) {
				for (int i = 0 + nfFrm + iPoint * nfPnt; i <= 4 + nfFrm + iPoint * nfPnt; i++)
					fprintf(ofile, " %6d", (int)(bigTableTm.at<float>(iFrame, i) + .5f));
				for (int i = 5 + nfFrm + iPoint * nfPnt; i < nfFrm + (iPoint + 1) * nfPnt; i++)
					fprintf(ofile, " %15.7e", bigTableTm.at<float>(iFrame, i));
			}
			fprintf(ofile, "\n");
		}
		if (ofile != NULL) fclose(ofile);
		std::cout << oSum << " is written.\n"; std::cout.flush();
	}  // end of output summary 

	// print result of all frames to a compact summary file
	if (oCpt.length() > 0) {
		FILE * ofile;
		fopen_s(&ofile, oCpt.c_str(), "w");
		//		fprintf(ofile, "  Frame NumPts       T_ReadImg      T_WriteTxt      T_WriteImg");
		for (int iPoint = 0; iPoint < nPoint; iPoint++) {
			//			fprintf(ofile, " X0_%03d Y0_%03d  W_%03d  H_%03d MT_%03d         W00_%03d         W01_%03d         W02_%03d         W10_%03d         W11_%03d         W12_%03d         W20_%03d         W21_%03d         Ecf_%03d         Xcr_%03d         Ycr_%03d         Rot_%03d        Tpre_%03d      Ttrack_%03d       Tpost_%03d",
			//				iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint);
			fprintf(ofile, "         Xcr_%03d         Ycr_%03d", iPoint, iPoint);
		}
		fprintf(ofile, "\n");
		for (int iFrame = 0; iFrame < nFrame; iFrame++) {
			//			fprintf(ofile, " %6d %6d", iFrame, nPoint);
			//			for (int i = 2; i < nfFrm; i++)
			//				fprintf(ofile, " %15.7f", bigTableTm.at<float>(iFrame, i));
			for (int iPoint = 0; iPoint < nPoint; iPoint++) {
				//				for (int i = 0 + nfFrm + iPoint * nfPnt; i <= 4 + nfFrm + iPoint * nfPnt; i++)
				//					fprintf(ofile, " %6d", (int)(bigTableTm.at<float>(iFrame, i) + .5f));
				//				for (int i = 5 + nfFrm + iPoint * nfPnt; i < nfFrm + (iPoint + 1) * nfPnt; i++)
				//					fprintf(ofile, " %15.7e", bigTableTm.at<float>(iFrame, i));
				for (int i = 14 + nfFrm + iPoint * nfPnt; i <= 15 + nfFrm + iPoint * nfPnt; i++)
					fprintf(ofile, " %15.7e", bigTableTm.at<float>(iFrame, i));
			}
			fprintf(ofile, "\n");
		}
		if (ofile != NULL) fclose(ofile);
		std::cout << oCpt << " is written.\n"; std::cout.flush();
		// xml compact
		vector<vector<cv::Point2f> >trackedImgPointsHistory(nFrame, vector<cv::Point2f>(nPoint));
		for (int iFrame = 0; iFrame < nFrame; iFrame++) {
			for (int iPoint = 0; iPoint < nPoint; iPoint++) {
				trackedImgPointsHistory[iFrame][iPoint].x = bigTableTm.at<float>(iFrame, nfFrm + 14 + iPoint * nfPnt);
				trackedImgPointsHistory[iFrame][iPoint].y = bigTableTm.at<float>(iFrame, nfFrm + 15 + iPoint * nfPnt);
			}
		}
		string fnameCompact = extFilenameRemoved(oCpt) + ".xml";
		cv::FileStorage ofsFileCompact(fnameCompact, cv::FileStorage::WRITE);
		ofsFileCompact << "numSteps" << nFrame;
		ofsFileCompact << "numPoints" << nPoint;
		ofsFileCompact << "VecVecPoint2f" << trackedImgPointsHistory;
		ofsFileCompact.release();

		// output matlab script
		string fnameTriangPointsMatlab = extFilenameRemoved(oCpt) + ".m";
		ofstream ofMat(fnameTriangPointsMatlab);
		cv::Mat trackedImgPointsHistoryMat(nFrame, nPoint, CV_32FC2);
		for (int iFrame = 0; iFrame < nFrame; iFrame++) {
			for (int iPoint = 0; iPoint < nPoint; iPoint++) {
				trackedImgPointsHistoryMat.at<cv::Point2f>(iFrame, iPoint) = trackedImgPointsHistory[iFrame][iPoint];
			}
		}
		ofMat << "ImgPointsHistory = " << trackedImgPointsHistoryMat << ";" << endl;
		ofMat << "ImgPointsHistory = reshape(ImgPointsHistory', [ 2 "
			<< trackedImgPointsHistoryMat.cols << " " // .cols is nPoint
			<< trackedImgPointsHistoryMat.rows << " ]);\n "; // .rows is nStep
		for (int i = 0; i < nPoint; i++) {
			ofMat << "fps = 29.97; % modify this number by yourself.\n";
			ofMat << "figure('name', 'Disp. of Point " << i + 1 << "');\n";
			ofMat << "xt(:) = (0:" << nFrame - 1 << ")/fps; ";
			ofMat << "yt(:) = ImgPointsHistory(1, " << i + 1 << ", :) - ImgPointsHistory(1, " << i + 1 << ", 1); \n";
			ofMat << "plot(xt,yt);\n";
			ofMat << "hold on;\n";
			ofMat << "yt(:) = ImgPointsHistory(2, " << i + 1 << ", :) - ImgPointsHistory(2, " << i + 1 << ", 1); \n";
			ofMat << "plot(xt,yt);\n";
			ofMat << "grid on; xlabel('Time (sec.)'); ylabel('Points Positions in Images'); \n";
			ofMat << "legend('ux', 'uy'); \n";
		}
		ofMat.close();
	}  // end of output summary 


	cv::destroyWindow("Tracked points");
	return 0;
}
