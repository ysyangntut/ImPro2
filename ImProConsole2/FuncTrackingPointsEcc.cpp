#include <iostream>
#include <fstream>
#include <cstdlib>
#include <cstdio>
#include <cmath>
#include <iomanip>
#include <string>
#include <vector>

#include <omp.h>

#include <opencv2/opencv.hpp>

#include "FileSeq.h"
#include "impro_util.h"

using namespace std;



const cv::String keys =
"{help h usage ?     |      | print this message   }"
"{fileList   fList   |      | file of file list. Each row is a file name without directory, assuming files are in the same directory with the file-list file.}"
"{imgPoints  imgPts  |      | xml file of image points generated by points picker. }"
"{tmpltFile  tmplts  |      | text file of template info. Each row is motion type, template width, height, search range x, y. If EOF, the rest info is the info in the last row.}"
"{outFrmDat  oDat    |      | output result file name of each frame. Actual file name is oDat_%06d.xml}"
"{outSum     oSum    |      | output summary file name.}"
"{outCompact oCpt    |      | output compact (only x y) summary file name.}"
"{outFrame   oFrame  |      | output picture which plots boxes on each point. Actual file name is oFrame_%06d.jpg}"
"{outVideo   oVideo  |      | output video which plots boxes on each point.}"
"{showBoxes  showBx  |      | 1 for showing tracked boxes }"
"{noAsk      noAsk   |      | 1 for automatic mode, not asking any questions for optional settings }"
;

int FuncTrackingPointsEcc(int argc, char** argv)
{
	// Arguments
	string fnameImgPts(""); // file of image points (of each point)
	string fnameTmplts(""); // file of template info (motion type, width, height, search range x, y)
	string oDat;            // file prefix of output data of each frame (each frame a file)
	string oFrame;          // file prefix of pictures of tracked boxes 
	string oVideo;          // file of video output  
	string oSum;            // file of summary result
	string oCpt;            // file of compact (only x and y for each point) of summary result
	bool   showBx;          // boolean of showing pictures of tracked boxes 

	int nFrame, nPoint;
	FileSeq fseq;
	cv::Mat imgPoints; // nPoint * 2, 32-bit float 
	vector<int> mTypes;  // nPoint sized 
	vector<int> maxSearchSizeX;  // if  maxSearchSizeX is 50, template width is 20, the search image width is 50 + 20 + 20 = 90
	vector<int> maxSearchSizeY;  // if  maxSearchSizeY is 50, template height is 20, the search image height is 50 + 20 + 20 = 90
	vector<cv::Rect> tmpltBoxes;  // nPoint sized, including template position, width and height

	cv::VideoWriter oVideoWriter;

	cv::Mat imgInit, imgCurr, imgBoxed;

	cv::Mat bigTableEcc; // Each row contains data of a frame.
	int nfFrm = 5;  // number of floats for each frame-based data
	int nfPnt = 20; // number of floats for each point-based data 
	// column 0: frame number (0-base index)
	// column 1: number of points
	// column 2: execution time (sec) to read image file
	// column 3: execution time (sec) to write frame result file 
	// column 4: execution time (sec) to write frame boxed image
	// column nfFrm +  0 + iPoint * nfPnt: template (roi) x (upper-left pixel)
	// column nfFrm +  1 + iPoint * nfPnt: template (roi) y (upper-left pixel)
	// column nfFrm +  2 + iPoint * nfPnt: template (roi) width
	// column nfFrm +  3 + iPoint * nfPnt: template (roi) height
	// column nfFrm +  4 + iPoint * nfPnt: ECC motion type 
	// column nfFrm +  5 + iPoint * nfPnt: warp matrix w00
	// column nfFrm +  6 + iPoint * nfPnt: warp matrix w01
	// column nfFrm +  7 + iPoint * nfPnt: warp matrix w02
	// column nfFrm +  8 + iPoint * nfPnt: warp matrix w10
	// column nfFrm +  9 + iPoint * nfPnt: warp matrix w11
	// column nfFrm + 10 + iPoint * nfPnt: warp matrix w12
	// column nfFrm + 11 + iPoint * nfPnt: warp matrix w20
	// column nfFrm + 12 + iPoint * nfPnt: warp matrix w21
	// column nfFrm + 13 + iPoint * nfPnt: ECC result coefficient
	// column nfFrm + 14 + iPoint * nfPnt: current image point x (pixel)
	// column nfFrm + 15 + iPoint * nfPnt: current image point y (pixel)
	// column nfFrm + 16 + iPoint * nfPnt: current image rotation (degree)
	// column nfFrm + 17 + iPoint * nfPnt: execution time (sec) for pre-processing
	// column nfFrm + 18 + iPoint * nfPnt: execution time (sec) for tracking (ECC)
	// column nfFrm + 19 + iPoint * nfPnt: execution time (sec) for post-processing

	// Get arguments
//	cv::CommandLineParser parser(argc, argv, keys);
	cv::CommandLineParser * pparser = NULL;
	if (argc >= 1) {
		pparser = new cv::CommandLineParser(argc, argv, keys);
	}

	if (pparser)
		if ((*pparser).has("help") || argc <= 1) {
			(*pparser).printMessage();
			std::cout << "\nUsage: \n";
			std::cout << "For example: TrackPointsEcc -fList=fList.txt -imgPts=imgPts.xml -motType=mType.txt -tmpSize=tmpltSize.txt \n";
		}

	// define list of picture files
	if (pparser)
		fseq.setFilesByListFile((*pparser).get<string>("fList"));
	if (fseq.num_files() == 0) {
		fseq.setDirFilesByConsole();
		if (fseq.num_files() <= 0) {
			std::cout << "User cancelled.\n"; cout.flush();
			return -1;
		}
	}
	printf("There are %d files. From %s to %s.\n", fseq.num_files(), fseq.fullPathOfFile(0).c_str(),
		fseq.fullPathOfFile(fseq.num_files() - 1).c_str());
	nFrame = fseq.num_files();

	// file name of image points ('g' for gui) --> fnameImgPts 
	fnameImgPts = string("");
	if (pparser)
		fnameImgPts = (*pparser).get<string>("imgPts");
	if (fnameImgPts.length() <= 0) {
		std::cout << "Enter xml file of image points (vector of Point2f, vector of rect, vector of motion type, generated by template picking) ('g' for gui dialog): ";
		fnameImgPts = readStringFromCin();
		if (fnameImgPts.length() == 1 && fnameImgPts[0] == 'g')
			fnameImgPts = uigetfile();
		if (fnameImgPts.length() == 0) {
			std::cout << "User cancelled.\n";
			return -1;
		}
	}
	// read image points
	cv::FileStorage fsImgPts(fnameImgPts, cv::FileStorage::READ);
	if (fsImgPts.isOpened() == false)
	{
		cerr << "Cannot open image point file " << fnameImgPts << endl;
		return -1;
	}
	vector<cv::Point2f> vecP2f;
	fsImgPts["VecPoint2f"] >> vecP2f;
	nPoint = (int)vecP2f.size();
	imgPoints = cv::Mat::zeros(nPoint, 2, CV_32F);
	for (int i = 0; i < nPoint; i++) {
		imgPoints.at<float>(i, 0) = vecP2f[i].x;
		imgPoints.at<float>(i, 1) = vecP2f[i].y;
	}
	printf("Image point %d: %6.1f %6.1f \n", 0, imgPoints.at<float>(0, 0), imgPoints.at<float>(0, 1));
	printf("Image point %d: %6.1f %6.1f \n", nPoint - 1, imgPoints.at<float>(nPoint - 1, 0), imgPoints.at<float>(nPoint - 1, 1));
	// template range (rect) 
	fsImgPts["VecRect"] >> tmpltBoxes;
	fsImgPts["VecMotionType"] >> mTypes;
	fsImgPts["VecSearchSizeX"] >> maxSearchSizeX;
	fsImgPts["VecSearchSizeY"] >> maxSearchSizeY;
	fsImgPts.release();

	//// template info (motion type, width, height, search range x, search range y)
	//mTypes.resize(nPoint);
	//maxSearchSizeX.resize(nPoint);
	//maxSearchSizeY.resize(nPoint);
	//tmpltBoxes.resize(nPoint);
	//// check -tmplts
	//if (pparser != NULL && pparser->has("tmplts")) {
	//	// read from assigned template info file (E.g., -tmplts=c:/folder/tmpltInfo.txt
	//	fnameTmplts = pparser->get<string>("tmplts");
	//}
	//ifstream ifTmplts(fnameTmplts);
	//// ask user to input tmplts file
	//while (ifTmplts.is_open() == false) {
	//	std::cout << "Enter file of template info file (each line: motType tmplt_width tmplt_height search_range_x search_range_y): ";
	//	fnameTmplts = readStringFromCin();
	//	ifTmplts.open(fnameTmplts);
	//	if (ifTmplts.is_open() == false) {
	//		std::cout << "Cannot open template info file " << fnameTmplts << endl;
	//		return -1;
	//	}
	//}
	//int motType = 0;  // motion type default value
	//int tmpltW = 50;  // template width default value
	//int tmpltH = 50;  // template height default value
	//int srchX = 50;   // search range x default value
	//int srchY = 50;   // search range y default value
	//int tmpInfo[5] = { motType, tmpltW, tmpltH, srchX, srchY }; // set tmpInfo to default values
	//for (int i = 0; i < nPoint; i++) {
	//	if (ifTmplts.eof() == false) {
	//		string strbufLine = readStringLineFromIstream(ifTmplts); // read motType tmpltW tmpltH srchX srchY
	//		vector<string> strings = readStringsFromStringLine(strbufLine);
	//		for (int j = 0; j < 5; j++) {
	//			// update tmpInfo. 
	//			// If not updated, tmpInfo remains either default values or previous values.
	//			if (strings.size() >= j + 1) {
	//				try { // try to convert each string to integer
	//					tmpInfo[j] = stoi(strings[j]);
	//				}
	//				catch (...) {
	//					cerr << "   Warning:Cannot parse template info Point " << i << ": " << strings[j] << endl;
	//					continue;
	//				}
	//			}
	//		}
	//	}
	//	// set this point to updated value 
	//	// or previous value if eof 
	//	// or default if never set
	//	mTypes[i] = tmpInfo[0];
	//	tmpltBoxes[i].width = tmpInfo[1];
	//	tmpltBoxes[i].height = tmpInfo[2];
	//	maxSearchSizeX[i] = tmpInfo[3];
	//	maxSearchSizeY[i] = tmpInfo[4];
	//} // end of loop of each point 

	// file name of output frame result ('g' for gui) --> oDat 
	if (pparser)
		oDat = (*pparser).get<string>("oDat");
	else
		oDat = string("");
	if (oDat.length() <= 0) {
		std::cout << "Enter file prefix of frame result (\"XXX\" for XXX_%06d.xml', 'g' for ui file dialog.): ";
		while (true) {
			oDat = readStringFromCin();
			if (oDat[0] == '#') continue;
			break;
		}
		if (oDat.length() == 1 && oDat[0] == 'g')
			oDat = uiputfile();
		if (oDat.length() == 0) {
			std::cout << "User chose to skip frame result.\n";
		}
	}

	// file name of output frame picture ('g' for gui) --> oFrame 
	if (pparser)
		oFrame = (*pparser).get<string>("oFrame");
	else
		oFrame = string("");
	if (oFrame.length() <= 0) {
		std::cout << "Enter file prefix of frame picture (\"XXX\" for XXX_%06d.JPG', single-char for not outputing, 'g' for ui file dialog.): ";
		oFrame = readStringFromCin();
		if (oFrame.length() == 1 && oFrame[0] == 'g')
			oFrame = uiputfile();
		if (oFrame.length() == 0 || (oFrame.length() == 1 && oFrame[0] == 'n')) {
			std::cout << "User chose to skip frame picture.\n";
			oFrame = string("");
		}
	}

	// file name of output video ('g' for gui) --> oVideo 
	if (pparser)
		oVideo = (*pparser).get<string>("oVideo");
	else
		oVideo = string("");
	if (oVideo.length() <= 0) {
		std::cout << "Enter output video file name, single-char for not outputing, 'g' for ui file dialog.): ";
		oVideo = readStringFromCin();
		if (oVideo.length() == 1 && oVideo[0] == 'g')
			oVideo = uiputfile();
		if (oVideo.length() <= 1) {
			std::cout << "User chose to skip video output.\n";
			oVideo = string("");
		}
	}

	// file name of output summary ('g' for gui) --> oSum 
	if (pparser)
		oSum = (*pparser).get<string>("oSum");
	else
		oSum = string("");
	if (oSum.length() <= 0) {
		std::cout << "Enter file of summary result ('g' for ui file dialog.): ";
		oSum = readStringFromCin();
		if (oSum.length() == 1 && oSum[0] == 'g')
			oSum = uiputfile();
		if (oSum.length() == 0) {
			std::cout << "User chose to skip summary file.\n";
		}
	}

	if (pparser)
		oCpt = (*pparser).get<string>("oCpt");
	else
		oCpt = string("");
	if (oCpt.length() <= 0) {
		std::cout << "Enter file of compact summary result (only image x y for each point)  ('g' for ui file dialog.): ";
		oCpt = readStringFromCin();
		if (oCpt.length() == 1 && oCpt[0] == 'g')
			oCpt = uiputfile();
		if (oCpt.length() == 0) {
			std::cout << "User chose to skip summary file.\n";
		}
	}

	// show boxes of tracked points --> showBx  
	std::string showBxStr = string("");
	if (pparser)
		showBxStr = (*pparser).get<string>("showBx");
	if (showBxStr.length() <= 0) {
		std::cout << "Show pictures of tracked points? (1 for true): ";
		showBxStr = readStringFromCin();
		if (showBxStr.length() >= 1 && showBxStr[0] == '1')
			showBx = true;
		else
			showBx = false;
	}

	printf("Motion type of point %d is %d \n", 0, mTypes[0]);
	printf("Motion type of point %d is %d \n", nPoint - 1, mTypes[nPoint - 1]);
	printf("Tmplt size of point %d is %d %d\n", 0, tmpltBoxes[0].width, tmpltBoxes[0].height);
	printf("Tmplt size of point %d is %d %d\n", nPoint - 1, tmpltBoxes[nPoint - 1].width, tmpltBoxes[nPoint - 1].height);

	// initialize big table  
	bigTableEcc = cv::Mat::zeros(nFrame, nfFrm + nfPnt * nPoint, CV_32F);

	// Frame 0 operations
	int iFrame = 0;
	double t_imreadFrm0 = (double)cv::getTickCount();
	imgInit = cv::imread(fseq.fullPathOfFile(iFrame), cv::IMREAD_GRAYSCALE);
	if (imgInit.cols <= 0 || imgInit.rows <= 0) {
		cerr << "Cannot read image " << iFrame << ": " << fseq.fullPathOfFile(iFrame) << ".\n";
		cerr.flush();
		return -1;
	}
	t_imreadFrm0 = ((double)cv::getTickCount() - t_imreadFrm0) / cv::getTickFrequency();
	bigTableEcc.at<float>(iFrame, 0) = (float)iFrame;
	bigTableEcc.at<float>(iFrame, 1) = (float)nPoint;
	bigTableEcc.at<float>(iFrame, 2) = (float)t_imreadFrm0; // execution time (sec) to read image file
	bigTableEcc.at<float>(iFrame, 3) = (float) 0.f; //	execution time (sec) to write frame result file 
	bigTableEcc.at<float>(iFrame, 4) = (float) 0.f; //	execution time (sec) to write frame boxed image
	for (int iPoint = 0; iPoint < nPoint; iPoint++)
	{
		cv::Point2f ref;
		//		tmpltBoxes[iPoint] = getTmpltRectFromImage(imgInit,
		//			cv::Point2f(imgPoints.at<float>(iPoint, 0), imgPoints.at<float>(iPoint, 1)),
		//			cv::Size(tmpltBoxes[iPoint].width, tmpltBoxes[iPoint].height),
		//			ref);
		bigTableEcc.at<float>(iFrame, nfFrm + 0 + iPoint * nfPnt) = (float)tmpltBoxes[iPoint].x;      // Will not change with iFrame
		bigTableEcc.at<float>(iFrame, nfFrm + 1 + iPoint * nfPnt) = (float)tmpltBoxes[iPoint].y;		 // Will not change with iFrame
		bigTableEcc.at<float>(iFrame, nfFrm + 2 + iPoint * nfPnt) = (float)tmpltBoxes[iPoint].width;	 // Will not change with iFrame
		bigTableEcc.at<float>(iFrame, nfFrm + 3 + iPoint * nfPnt) = (float)tmpltBoxes[iPoint].height; // Will not change with iFrame
		bigTableEcc.at<float>(iFrame, nfFrm + 4 + iPoint * nfPnt) = (float)mTypes[iPoint];            // Will not change with iFrame
		bigTableEcc.at<float>(iFrame, nfFrm + 5 + iPoint * nfPnt) = 1.0f;
		bigTableEcc.at<float>(iFrame, nfFrm + 6 + iPoint * nfPnt) = 0.0f;
		bigTableEcc.at<float>(iFrame, nfFrm + 7 + iPoint * nfPnt) = (float)tmpltBoxes[iPoint].x;
		bigTableEcc.at<float>(iFrame, nfFrm + 8 + iPoint * nfPnt) = 0.0f;
		bigTableEcc.at<float>(iFrame, nfFrm + 9 + iPoint * nfPnt) = 1.0f;
		bigTableEcc.at<float>(iFrame, nfFrm + 10 + iPoint * nfPnt) = (float)tmpltBoxes[iPoint].y;
		bigTableEcc.at<float>(iFrame, nfFrm + 11 + iPoint * nfPnt) = 0.0f;
		bigTableEcc.at<float>(iFrame, nfFrm + 12 + iPoint * nfPnt) = 0.0f;
		bigTableEcc.at<float>(iFrame, nfFrm + 13 + iPoint * nfPnt) = 1.0f;
		bigTableEcc.at<float>(iFrame, nfFrm + 14 + iPoint * nfPnt) = imgPoints.at<float>(iPoint, 0);
		bigTableEcc.at<float>(iFrame, nfFrm + 15 + iPoint * nfPnt) = imgPoints.at<float>(iPoint, 1);
		bigTableEcc.at<float>(iFrame, nfFrm + 16 + iPoint * nfPnt) = 0.0f;
		bigTableEcc.at<float>(iFrame, nfFrm + 17 + iPoint * nfPnt) = 0.0f;	// execution time (sec) for pre-processing
		bigTableEcc.at<float>(iFrame, nfFrm + 18 + iPoint * nfPnt) = 0.0f;	// execution time (sec) for tracking (ECC)
		bigTableEcc.at<float>(iFrame, nfFrm + 19 + iPoint * nfPnt) = 0.0f;	// execution time (sec) for post-processing
	}

	// Main loop. 
	float ecc_threshold = 0.9f;
	int64 tickCountStart = cv::getTickCount();
	for (int iFrame = 1; iFrame < nFrame; iFrame++)
	{
		// read image
		double t_imreadFrm = (double)cv::getTickCount();
		fseq.waitForFile(iFrame);
		imgBoxed = cv::imread(fseq.fullPathOfFile(iFrame), cv::IMREAD_COLOR);
		cv::cvtColor(imgBoxed, imgCurr, cv::COLOR_BGR2GRAY);
		if (imgCurr.cols <= 0 || imgCurr.rows <= 0) {
			cerr << "Cannot read image " << iFrame << ": " << fseq.fullPathOfFile(iFrame) << ".\n";
			cerr.flush();
			return -1;
		}
		t_imreadFrm = ((double)cv::getTickCount() - t_imreadFrm) / cv::getTickFrequency();

		bigTableEcc.at<float>(iFrame, 0) = (float)iFrame;
		bigTableEcc.at<float>(iFrame, 1) = (float)nPoint;
		bigTableEcc.at<float>(iFrame, 2) = (float)t_imreadFrm0; // execution time (sec) to read image file
		bigTableEcc.at<float>(iFrame, 3) = (float) 0.f; //	execution time (sec) to write frame result file 
		bigTableEcc.at<float>(iFrame, 4) = (float) 0.f; //	execution time (sec) to write frame boxed image

// If OpenMP is disabled, probably it is because ECC computing time is relatively small, openMP is not helping significantly but increasing threading load.
//#pragma omp parallel for
		for (int iPoint = 0; iPoint < nPoint; iPoint++)
		{
			// timing pre-processing
			double t_point_pre = (double)cv::getTickCount();

			// template
			bigTableEcc.at<float>(iFrame, nfFrm + 0 + iPoint * nfPnt) = (float)tmpltBoxes[iPoint].x;      // Will not change with iFrame
			bigTableEcc.at<float>(iFrame, nfFrm + 1 + iPoint * nfPnt) = (float)tmpltBoxes[iPoint].y;		// Will not change with iFrame
			bigTableEcc.at<float>(iFrame, nfFrm + 2 + iPoint * nfPnt) = (float)tmpltBoxes[iPoint].width;	// Will not change with iFrame
			bigTableEcc.at<float>(iFrame, nfFrm + 3 + iPoint * nfPnt) = (float)tmpltBoxes[iPoint].height; // Will not change with iFrame

			// motion type 
			bigTableEcc.at<float>(iFrame, nfFrm + 4 + iPoint * nfPnt) = (float)mTypes[iPoint];

			// initial guess of warp
			cv::Mat warp(3, 3, CV_32F);

			// initial guess of warp is the previous warp (find closest frame that ECC coefficient > 0.9)
			int iFramePreviousValid;
			for (iFramePreviousValid = iFrame - 1; iFramePreviousValid > 0; iFramePreviousValid--) {
				if (bigTableEcc.at<float>(iFrame - 1, nfFrm + 13 + iPoint * nfPnt) >= ecc_threshold)
					break;
			}
			warp.at<float>(0, 0) = bigTableEcc.at<float>(iFramePreviousValid, nfFrm + 5 + iPoint * nfPnt);
			warp.at<float>(0, 1) = bigTableEcc.at<float>(iFramePreviousValid, nfFrm + 6 + iPoint * nfPnt);
			warp.at<float>(0, 2) = bigTableEcc.at<float>(iFramePreviousValid, nfFrm + 7 + iPoint * nfPnt);
			warp.at<float>(1, 0) = bigTableEcc.at<float>(iFramePreviousValid, nfFrm + 8 + iPoint * nfPnt);
			warp.at<float>(1, 1) = bigTableEcc.at<float>(iFramePreviousValid, nfFrm + 9 + iPoint * nfPnt);
			warp.at<float>(1, 2) = bigTableEcc.at<float>(iFramePreviousValid, nfFrm + 10 + iPoint * nfPnt);
			warp.at<float>(2, 0) = bigTableEcc.at<float>(iFramePreviousValid, nfFrm + 11 + iPoint * nfPnt);
			warp.at<float>(2, 1) = bigTableEcc.at<float>(iFramePreviousValid, nfFrm + 12 + iPoint * nfPnt);
			warp.at<float>(2, 2) = 1.0f;

			// timing pre-processing
			t_point_pre = ((double)cv::getTickCount() - t_point_pre) / cv::getTickFrequency();

			//			cv::imshow("TMPLT", imgInit(tmpltBoxes[iPoint])); 
			//			cv::waitKey(0); 
			//			cv::destroyWindow("TMPLT"); 
			//			std::cout << "Motion type: " << bigTableEcc.at<float>(iFrame, nfFrm +  4 + iPoint * nfPnt) << endl;
			//			cout.flush(); 

						// timing tracking
			double t_point_tracking = (double)cv::getTickCount();

			// ECC Tracking 
			int motion_type = (int)bigTableEcc.at<float>(iFrame, nfFrm + 4 + iPoint * nfPnt);
			double ecc_Coef;
			cv::Mat warpX3;
			if (motion_type == cv::MOTION_HOMOGRAPHY)
				warpX3 = warp(cv::Rect(0, 0, 3, 3));
			else
				warpX3 = warp(cv::Rect(0, 0, 3, 2));
			//				std::cout << "Warp before: \n" << warp << endl;
			try {
				int criteriaCount = 50;
				double eps = 0.01;
				int cloneImagesBeforeEcc = 1;
				if (cloneImagesBeforeEcc == 0) {
					ecc_Coef = cv::findTransformECC(
						imgInit(tmpltBoxes[iPoint]),
						imgCurr,
						warpX3, // warp matrix (input: initial guess, output: updated)
						motion_type,   // motion type
						cv::TermCriteria(cv::TermCriteria::COUNT + cv::TermCriteria::EPS, criteriaCount, eps));
				}
				else if (cloneImagesBeforeEcc == 1) {
					// copy to smaller clone images
					int maxMoveX = maxSearchSizeX[iPoint];
					int maxMoveY = maxSearchSizeY[iPoint];
					cv::Point2f refPoint;
					cv::Mat imgTmplt, imgSearch;
					imgInit(tmpltBoxes[iPoint]).copyTo(imgTmplt);
					cv::Rect rectSearch =
						getTmpltRectFromImage(imgCurr, cv::Point2f(warpX3.at<float>(0, 2), warpX3.at<float>(1, 2)),
							cv::Size(imgTmplt.cols + 2 * maxMoveX, imgTmplt.rows + 2 * maxMoveY), refPoint);
					imgCurr(rectSearch).copyTo(imgSearch);
					warpX3.at<float>(0, 2) -= rectSearch.x;
					warpX3.at<float>(1, 2) -= rectSearch.y;
					ecc_Coef = cv::findTransformECC(
						imgTmplt,
						imgSearch,
						warpX3, // warp matrix (input: initial guess, output: updated)
						motion_type,   // motion type
						cv::TermCriteria(cv::TermCriteria::COUNT + cv::TermCriteria::EPS, criteriaCount, eps));
					warpX3.at<float>(0, 2) += rectSearch.x;
					warpX3.at<float>(1, 2) += rectSearch.y;
				}
			}
			catch (...) {
				// If ECC fails, use previous frame result with coefficiet = 0.0f
				warp.at<float>(0, 0) = bigTableEcc.at<float>(iFrame - 1, nfFrm + 5 + iPoint * nfPnt);
				warp.at<float>(0, 1) = bigTableEcc.at<float>(iFrame - 1, nfFrm + 6 + iPoint * nfPnt);
				warp.at<float>(0, 2) = bigTableEcc.at<float>(iFrame - 1, nfFrm + 7 + iPoint * nfPnt);
				warp.at<float>(1, 0) = bigTableEcc.at<float>(iFrame - 1, nfFrm + 8 + iPoint * nfPnt);
				warp.at<float>(1, 1) = bigTableEcc.at<float>(iFrame - 1, nfFrm + 9 + iPoint * nfPnt);
				warp.at<float>(1, 2) = bigTableEcc.at<float>(iFrame - 1, nfFrm + 10 + iPoint * nfPnt);
				warp.at<float>(2, 0) = bigTableEcc.at<float>(iFrame - 1, nfFrm + 11 + iPoint * nfPnt);
				warp.at<float>(2, 1);  bigTableEcc.at<float>(iFrame - 1, nfFrm + 12 + iPoint * nfPnt);
				ecc_Coef = 0.f;
			}

			t_point_tracking = ((double)cv::getTickCount() - t_point_tracking) / cv::getTickFrequency();

			//				std::cout << "Warp after: \n" << warp << endl;
			//				cout.flush(); 
			//				system("pause"); 

						// timing post-processing
			double t_point_post = (double)cv::getTickCount();

			// Update result to big table
			bigTableEcc.at<float>(iFrame, nfFrm + 5 + iPoint * nfPnt) = warp.at<float>(0, 0);
			bigTableEcc.at<float>(iFrame, nfFrm + 6 + iPoint * nfPnt) = warp.at<float>(0, 1);
			bigTableEcc.at<float>(iFrame, nfFrm + 7 + iPoint * nfPnt) = warp.at<float>(0, 2);
			bigTableEcc.at<float>(iFrame, nfFrm + 8 + iPoint * nfPnt) = warp.at<float>(1, 0);
			bigTableEcc.at<float>(iFrame, nfFrm + 9 + iPoint * nfPnt) = warp.at<float>(1, 1);
			bigTableEcc.at<float>(iFrame, nfFrm + 10 + iPoint * nfPnt) = warp.at<float>(1, 2);
			bigTableEcc.at<float>(iFrame, nfFrm + 11 + iPoint * nfPnt) = warp.at<float>(2, 0);
			bigTableEcc.at<float>(iFrame, nfFrm + 12 + iPoint * nfPnt) = warp.at<float>(2, 1);
			bigTableEcc.at<float>(iFrame, nfFrm + 13 + iPoint * nfPnt) = (float)ecc_Coef;

			// Find current image point by warp matrix multiplication 
			cv::Mat refPoint(3, 1, CV_32F);
			refPoint.at<float>(0, 0) = imgPoints.at<float>(iPoint, 0) - (float)tmpltBoxes[iPoint].x;
			refPoint.at<float>(1, 0) = imgPoints.at<float>(iPoint, 1) - (float)tmpltBoxes[iPoint].y;
			refPoint.at<float>(2, 0) = 1.f;
			refPoint = warp * refPoint;
			bigTableEcc.at<float>(iFrame, nfFrm + 14 + iPoint * nfPnt) = refPoint.at<float>(0, 0);
			bigTableEcc.at<float>(iFrame, nfFrm + 15 + iPoint * nfPnt) = refPoint.at<float>(1, 0);

			// Find rotation by cv::Rodrigues (in degree)
			cv::Mat m33 = cv::Mat::eye(3, 3, CV_32F), rv3 = cv::Mat::zeros(3, 1, CV_32F);
			m33.at<float>(0, 0) = warp.at<float>(0, 0);
			m33.at<float>(0, 1) = warp.at<float>(0, 1);
			m33.at<float>(1, 0) = warp.at<float>(1, 0);
			m33.at<float>(1, 1) = warp.at<float>(1, 1);
			cv::Rodrigues(m33, rv3);
			bigTableEcc.at<float>(iFrame, nfFrm + 16 + iPoint * nfPnt) = rv3.at<float>(2, 0) * 180.f / 3.141592653589f;

			t_point_post = ((double)cv::getTickCount() - t_point_post) / cv::getTickFrequency();

			bigTableEcc.at<float>(iFrame, nfFrm + 17 + iPoint * nfPnt) = (float)t_point_pre;      // execution time (sec) for pre-processing 
			bigTableEcc.at<float>(iFrame, nfFrm + 18 + iPoint * nfPnt) = (float)t_point_tracking; // execution time (sec) for tracking (ECC)
			bigTableEcc.at<float>(iFrame, nfFrm + 19 + iPoint * nfPnt) = (float)t_point_post;     // execution time (sec) for post-processing

		} // next point

		// print marked boxes picture of each frame
		double t_writeImg = (double)cv::getTickCount();
		if (oFrame.length() > 0 || showBx == true || oVideo.length() > 0) {
			// plot boxes on imgBoxed
			for (int iPoint = 0; iPoint < nPoint; iPoint++) {
				// get warp matrix of iPoint of iFrame
				cv::Mat warp(3, 3, CV_32F);
				warp.at<float>(0, 0) = bigTableEcc.at<float>(iFrame, nfFrm + 5 + iPoint * nfPnt);
				warp.at<float>(0, 1) = bigTableEcc.at<float>(iFrame, nfFrm + 6 + iPoint * nfPnt);
				warp.at<float>(0, 2) = bigTableEcc.at<float>(iFrame, nfFrm + 7 + iPoint * nfPnt);
				warp.at<float>(1, 0) = bigTableEcc.at<float>(iFrame, nfFrm + 8 + iPoint * nfPnt);
				warp.at<float>(1, 1) = bigTableEcc.at<float>(iFrame, nfFrm + 9 + iPoint * nfPnt);
				warp.at<float>(1, 2) = bigTableEcc.at<float>(iFrame, nfFrm + 10 + iPoint * nfPnt);
				warp.at<float>(2, 0) = bigTableEcc.at<float>(iFrame, nfFrm + 11 + iPoint * nfPnt);
				warp.at<float>(2, 1) = bigTableEcc.at<float>(iFrame, nfFrm + 12 + iPoint * nfPnt);
				warp.at<float>(2, 2) = 1.0f;
				// define un-warp box
				cv::Mat p4m(3, 5, CV_32F);
				p4m.at<float>(0, 0) = 0.f;
				p4m.at<float>(1, 0) = 0.f;
				p4m.at<float>(2, 0) = 1.f;
				p4m.at<float>(0, 1) = 0.f;
				p4m.at<float>(1, 1) = bigTableEcc.at<float>(iFrame, nfFrm + 3 + iPoint * nfPnt); // h
				p4m.at<float>(2, 1) = 1.f;
				p4m.at<float>(0, 2) = bigTableEcc.at<float>(iFrame, nfFrm + 2 + iPoint * nfPnt); // w
				p4m.at<float>(1, 2) = bigTableEcc.at<float>(iFrame, nfFrm + 3 + iPoint * nfPnt); // h
				p4m.at<float>(2, 2) = 1.f;
				p4m.at<float>(0, 3) = bigTableEcc.at<float>(iFrame, nfFrm + 2 + iPoint * nfPnt); // w
				p4m.at<float>(1, 3) = 0.f;
				p4m.at<float>(2, 3) = 1.f;
				p4m.at<float>(0, 4) = imgPoints.at<float>(iPoint, 0) - (float)tmpltBoxes[iPoint].x;
				p4m.at<float>(1, 4) = imgPoints.at<float>(iPoint, 1) - (float)tmpltBoxes[iPoint].y;
				p4m.at<float>(2, 4) = 1.f;
				// calculate warpped box
				p4m = warp * p4m;
				p4m.at<float>(0, 0) /= p4m.at<float>(2, 0);
				p4m.at<float>(0, 1) /= p4m.at<float>(2, 1);
				p4m.at<float>(0, 2) /= p4m.at<float>(2, 2);
				p4m.at<float>(0, 3) /= p4m.at<float>(2, 3);
				p4m.at<float>(0, 4) /= p4m.at<float>(2, 4);
				p4m.at<float>(1, 0) /= p4m.at<float>(2, 0);
				p4m.at<float>(1, 1) /= p4m.at<float>(2, 1);
				p4m.at<float>(1, 2) /= p4m.at<float>(2, 2);
				p4m.at<float>(1, 3) /= p4m.at<float>(2, 3);
				p4m.at<float>(1, 4) /= p4m.at<float>(2, 4);
				// plot box 
				int shift = 3, shFact = 1 << shift;
				cv::Point p0 = cv::Point((int)(p4m.at<float>(0, 0) * shFact + .5), (int)(p4m.at<float>(1, 0) * shFact + .5));
				cv::Point p1 = cv::Point((int)(p4m.at<float>(0, 1) * shFact + .5), (int)(p4m.at<float>(1, 1) * shFact + .5));
				cv::Point p2 = cv::Point((int)(p4m.at<float>(0, 2) * shFact + .5), (int)(p4m.at<float>(1, 2) * shFact + .5));
				cv::Point p3 = cv::Point((int)(p4m.at<float>(0, 3) * shFact + .5), (int)(p4m.at<float>(1, 3) * shFact + .5));
				cv::Point p4 = cv::Point((int)(p4m.at<float>(0, 4) * shFact + .5), (int)(p4m.at<float>(1, 4) * shFact + .5));
				int thickness = 2;
				int linetype = cv::LINE_AA;
				if (bigTableEcc.at<float>(iFrame, nfFrm + 13 + iPoint * nfPnt) <= 0.0f)
					thickness = 1;
				cv::line(imgBoxed, p0, p1, cv::Scalar(127, 255, 127), thickness, linetype, shift);
				cv::line(imgBoxed, p1, p2, cv::Scalar(127, 255, 127), thickness, linetype, shift);
				cv::line(imgBoxed, p2, p3, cv::Scalar(127, 255, 127), thickness, linetype, shift);
				cv::line(imgBoxed, p3, p0, cv::Scalar(127, 255, 127), thickness, linetype, shift);
				if (bigTableEcc.at<float>(iFrame, nfFrm + 13 + iPoint * nfPnt) > ecc_threshold) {
					cv::line(imgBoxed, p0, p4, cv::Scalar(127, 255, 127), 1, linetype, shift);
					cv::line(imgBoxed, p1, p4, cv::Scalar(127, 255, 127), 1, linetype, shift);
					cv::line(imgBoxed, p2, p4, cv::Scalar(127, 255, 127), 1, linetype, shift);
					cv::line(imgBoxed, p3, p4, cv::Scalar(127, 255, 127), 1, linetype, shift);
				}

			} // end of point loop

			if (oFrame.length() > 1) {
				char ofsFrame[1000];
                snprintf(ofsFrame, 1000, "_%06d.jpg", iFrame);
				std::string ofsFrameStr = oFrame + std::string(ofsFrame);
				cv::imwrite(ofsFrameStr, imgBoxed);
			}
			if (oVideo.length() > 1 && iFrame <= 1) {
				int f4cc = preferredFourcc();
				oVideoWriter.open(oVideo, f4cc, 30.0, imgBoxed.size());
			}
			if (oVideo.length() > 0 && oVideo[0] != 'n' && oVideoWriter.isOpened())
				oVideoWriter << imgBoxed;

			// show boxes 
			if (showBx == true) {
				cv::Mat imgShow;
				int maxW = 1280, maxH = 720;
				float facH = maxH * 1.0f / imgBoxed.rows;
				float facW = maxW * 1.0f / imgBoxed.cols;
				float fac = facH > facW ? facW : facH;
				cv::resize(imgBoxed, imgShow, cv::Size(0, 0), fac, fac, cv::INTER_LANCZOS4);
				cv::imshow("Tracked points", imgShow);
				cv::waitKey(1);
			}
		} // end if output box plot
		t_writeImg = ((double)cv::getTickCount() - t_writeImg) / cv::getTickFrequency();
		bigTableEcc.at<float>(iFrame, 4) = (float)t_writeImg; //	execution time (sec) to write frame boxed image

		// print result of this frame to a file
		double t_writeTxt = (double)cv::getTickCount();
		if (oDat.length() > 0) {
			// txt file
			char ofsFname[1000];
            snprintf(ofsFname, 1000, "_%06d.txt", iFrame);
			std::string ofsFnameStr = oDat + std::string(ofsFname);
			FILE * ofile;
			fopen_s(&ofile, ofsFnameStr.c_str(), "w");
			fprintf(ofile, "  Frame NumPts       T_ReadImg      T_WriteTxt      T_WriteImg");
			for (int iPoint = 0; iPoint < nPoint; iPoint++) {
				fprintf(ofile, " X0_%03d Y0_%03d  W_%03d  H_%03d MT_%03d         W00_%03d         W01_%03d         W02_%03d         W10_%03d         W11_%03d         W12_%03d         W20_%03d         W21_%03d         Ecf_%03d         Xcr_%03d         Ycr_%03d         Rot_%03d        Tpre_%03d      Ttrack_%03d       Tpost_%03d",
					iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint);
			}
			fprintf(ofile, "\n");
			fprintf(ofile, " %6d %6d", iFrame, nPoint);
			for (int i = 2; i < nfFrm; i++)
				fprintf(ofile, " %15.7f", bigTableEcc.at<float>(iFrame, i));
			for (int iPoint = 0; iPoint < nPoint; iPoint++) {
				for (int i = 0 + nfFrm + iPoint * nfPnt; i <= 4 + nfFrm + iPoint * nfPnt; i++)
					fprintf(ofile, " %6d", (int)(bigTableEcc.at<float>(iFrame, i) + .5f));
				for (int i = 5 + nfFrm + iPoint * nfPnt; i < nfFrm + (iPoint + 1) * nfPnt; i++)
					fprintf(ofile, " %15.7e", bigTableEcc.at<float>(iFrame, i));
			}
			fprintf(ofile, "\n");
			std::fclose(ofile);
			// xml file
			vector<cv::Point2f> trackedImgPoints(nPoint);
			for (int iPoint = 0; iPoint < nPoint; iPoint++) {
				trackedImgPoints[iPoint].x = bigTableEcc.at<float>(iFrame, nfFrm + 14 + iPoint * nfPnt);
				trackedImgPoints[iPoint].y = bigTableEcc.at<float>(iFrame, nfFrm + 15 + iPoint * nfPnt);
			}
            snprintf(ofsFname, 1000, "_%06d.xml", iFrame);
			cv::FileStorage ofsFileTrackedImgPoints(oDat + ofsFname, cv::FileStorage::WRITE);
			ofsFileTrackedImgPoints << "VecPoint2f" << trackedImgPoints;
			ofsFileTrackedImgPoints.release();
		} // end of output frame result
		t_writeTxt = ((double)cv::getTickCount() - t_writeTxt) / cv::getTickFrequency();
		bigTableEcc.at<float>(iFrame, 3) = (float)t_writeTxt; //	execution time (sec) to write frame result file 

		if (iFrame % 10 == 0) {
			std::cout << "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
				"\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b";
			int64 tickCountFrameEnd = cv::getTickCount();
			float timePast = (float)((tickCountFrameEnd - tickCountStart) / cv::getTickFrequency());
			float timeTotalEstimated = timePast / ((iFrame + 1) * 1.0f / nFrame);
			float timeReamining = timeTotalEstimated - timePast;
			printf("Frame %06d/%06d. %6d points/sec. Time remaining: %6d sec.", iFrame, nFrame,
				(int)(nPoint * (iFrame + 1) / timePast), (int)(timeReamining + .5f));
		}

	} // next frame 

	// print result of all frames to a summary file
	if (oSum.length() > 0) {
		FILE * ofile;
		fopen_s(&ofile, oSum.c_str(), "w");
		fprintf(ofile, "  Frame NumPts       T_ReadImg      T_WriteTxt      T_WriteImg");
		for (int iPoint = 0; iPoint < nPoint; iPoint++) {
			fprintf(ofile, " X0_%03d Y0_%03d  W_%03d  H_%03d MT_%03d         W00_%03d         W01_%03d         W02_%03d         W10_%03d         W11_%03d         W12_%03d         W20_%03d         W21_%03d         Ecf_%03d         Xcr_%03d         Ycr_%03d         Rot_%03d        Tpre_%03d      Ttrack_%03d       Tpost_%03d",
				iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint);
		}
		fprintf(ofile, "\n");
		for (int iFrame = 0; iFrame < nFrame; iFrame++) {
			fprintf(ofile, " %6d %6d", iFrame, nPoint);
			for (int i = 2; i < nfFrm; i++)
				fprintf(ofile, " %15.7f", bigTableEcc.at<float>(iFrame, i));
			for (int iPoint = 0; iPoint < nPoint; iPoint++) {
				for (int i = 0 + nfFrm + iPoint * nfPnt; i <= 4 + nfFrm + iPoint * nfPnt; i++)
					fprintf(ofile, " %6d", (int)(bigTableEcc.at<float>(iFrame, i) + .5f));
				for (int i = 5 + nfFrm + iPoint * nfPnt; i < nfFrm + (iPoint + 1) * nfPnt; i++)
					fprintf(ofile, " %15.7e", bigTableEcc.at<float>(iFrame, i));
			}
			fprintf(ofile, "\n");
		}
		fclose(ofile);
		std::cout << oSum << " is written.\n"; cout.flush();
	}  // end of output summary 

	// print result of all frames to a compact summary file
	if (oCpt.length() > 0) {
		FILE * ofile;
		fopen_s(&ofile, oCpt.c_str(), "w");
		//		fprintf(ofile, "  Frame NumPts       T_ReadImg      T_WriteTxt      T_WriteImg");
		for (int iPoint = 0; iPoint < nPoint; iPoint++) {
			//			fprintf(ofile, " X0_%03d Y0_%03d  W_%03d  H_%03d MT_%03d         W00_%03d         W01_%03d         W02_%03d         W10_%03d         W11_%03d         W12_%03d         W20_%03d         W21_%03d         Ecf_%03d         Xcr_%03d         Ycr_%03d         Rot_%03d        Tpre_%03d      Ttrack_%03d       Tpost_%03d",
			//				iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint);
			fprintf(ofile, "         Xcr_%03d         Ycr_%03d", iPoint, iPoint);
		}
		fprintf(ofile, "\n");
		for (int iFrame = 0; iFrame < nFrame; iFrame++) {
			//			fprintf(ofile, " %6d %6d", iFrame, nPoint);
			//			for (int i = 2; i < nfFrm; i++)
			//				fprintf(ofile, " %15.7f", bigTableEcc.at<float>(iFrame, i));
			for (int iPoint = 0; iPoint < nPoint; iPoint++) {
				//				for (int i = 0 + nfFrm + iPoint * nfPnt; i <= 4 + nfFrm + iPoint * nfPnt; i++)
				//					fprintf(ofile, " %6d", (int)(bigTableEcc.at<float>(iFrame, i) + .5f));
				//				for (int i = 5 + nfFrm + iPoint * nfPnt; i < nfFrm + (iPoint + 1) * nfPnt; i++)
				//					fprintf(ofile, " %15.7e", bigTableEcc.at<float>(iFrame, i));
				for (int i = 14 + nfFrm + iPoint * nfPnt; i <= 15 + nfFrm + iPoint * nfPnt; i++)
					fprintf(ofile, " %15.7e", bigTableEcc.at<float>(iFrame, i));
			}
			fprintf(ofile, "\n");
		}
		fclose(ofile);
		std::cout << oCpt << " is written.\n"; cout.flush();
		// xml compact
		vector<vector<cv::Point2f> >trackedImgPointsHistory(nFrame, vector<cv::Point2f>(nPoint));
		for (int iFrame = 0; iFrame < nFrame; iFrame++) {
			for (int iPoint = 0; iPoint < nPoint; iPoint++) {
				trackedImgPointsHistory[iFrame][iPoint].x = bigTableEcc.at<float>(iFrame, nfFrm + 14 + iPoint * nfPnt);
				trackedImgPointsHistory[iFrame][iPoint].y = bigTableEcc.at<float>(iFrame, nfFrm + 15 + iPoint * nfPnt);
			}
		}
		string fnameCompact = extFilenameRemoved(oCpt) + ".xml";
		cv::FileStorage ofsFileCompact(fnameCompact, cv::FileStorage::WRITE);
		ofsFileCompact << "numSteps" << nFrame;
		ofsFileCompact << "numPoints" << nPoint;
		ofsFileCompact << "VecVecPoint2f" << trackedImgPointsHistory;
		ofsFileCompact.release();
	}  // end of output summary 

	cv::destroyWindow("Tracked points");
	return 0;
}

//const cv::String keys =
//"{help h usage ?     |      | print this message   }"
//"{fileList   fList   |      | file of file list. Each row is a file name without directory, assuming files are in the same directory with the file-list file.}"
//"{imgPoints  imgPts  |      | xml file of image points generated by points picker. }"
//"{tmpltFile  tmplts  |      | text file of template info. Each row is motion type, template width, height, search range x, y. If EOF, the rest info is the info in the last row.}"
//"{outFrmDat  oDat    |      | output result file name of each frame. Actual file name is oDat_%06d.txt}"
//"{outSum     oSum    |      | output summary file name.}"
//"{outCompact oCpt    |      | output compact (only x y) summary file name.}"
//"{outFrame   oFrame  |      | output picture which plots boxes on each point. Actual file name is oFrame_%06d.jpg}"
//"{outVideo   oVideo  |      | output video which plots boxes on each point.}"
//"{showBoxes  showBx  |      | 1 for showing tracked boxes }"
//"{noAsk      noAsk   |      | 1 for automatic mode, not asking any questions for optional settings }"
//;
//
int _old_FuncTrackingPointsEcc(int argc, char** argv)
{
	// Arguments
	string fnameImgPts(""); // file of image points (of each point)
	string fnameTmplts(""); // file of template info (motion type, width, height, search range x, y)
	string oDat;            // file prefix of output data of each frame (each frame a file)
	string oFrame;          // file prefix of pictures of tracked boxes 
	string oVideo;          // file of video output  
	string oSum;            // file of summary result
	string oCpt;            // file of compact (only x and y for each point) of summary result
	bool   showBx;          // boolean of showing pictures of tracked boxes 

	int nFrame, nPoint;
	FileSeq fseq;
	cv::Mat imgPoints; // nPoint * 2, 32-bit float 
	vector<int> mTypes;  // nPoint sized 
	vector<int> maxSearchSizeX;  // if  maxSearchSizeX is 50, template width is 20, the search image width is 50 + 20 + 20 = 90
	vector<int> maxSearchSizeY;  // if  maxSearchSizeY is 50, template height is 20, the search image height is 50 + 20 + 20 = 90
	vector<cv::Rect> tmpltBoxes;  // nPoint sized, including template position, width and height

	cv::VideoWriter oVideoWriter; 

	cv::Mat imgInit, imgCurr, imgBoxed;

	cv::Mat bigTableEcc; // Each row contains data of a frame.
	int nfFrm = 5;  // number of floats for each frame-based data
	int nfPnt = 20; // number of floats for each point-based data 
	// column 0: frame number (0-base index)
	// column 1: number of points
	// column 2: execution time (sec) to read image file
	// column 3: execution time (sec) to write frame result file 
	// column 4: execution time (sec) to write frame boxed image
	// column nfFrm +  0 + iPoint * nfPnt: template (roi) x (upper-left pixel)
	// column nfFrm +  1 + iPoint * nfPnt: template (roi) y (upper-left pixel)
	// column nfFrm +  2 + iPoint * nfPnt: template (roi) width
	// column nfFrm +  3 + iPoint * nfPnt: template (roi) height
	// column nfFrm +  4 + iPoint * nfPnt: ECC motion type 
	// column nfFrm +  5 + iPoint * nfPnt: warp matrix w00
	// column nfFrm +  6 + iPoint * nfPnt: warp matrix w01
	// column nfFrm +  7 + iPoint * nfPnt: warp matrix w02
	// column nfFrm +  8 + iPoint * nfPnt: warp matrix w10
	// column nfFrm +  9 + iPoint * nfPnt: warp matrix w11
	// column nfFrm + 10 + iPoint * nfPnt: warp matrix w12
	// column nfFrm + 11 + iPoint * nfPnt: warp matrix w20
	// column nfFrm + 12 + iPoint * nfPnt: warp matrix w21
	// column nfFrm + 13 + iPoint * nfPnt: ECC result coefficient
	// column nfFrm + 14 + iPoint * nfPnt: current image point x (pixel)
	// column nfFrm + 15 + iPoint * nfPnt: current image point y (pixel)
	// column nfFrm + 16 + iPoint * nfPnt: current image rotation (degree)
	// column nfFrm + 17 + iPoint * nfPnt: execution time (sec) for pre-processing
	// column nfFrm + 18 + iPoint * nfPnt: execution time (sec) for tracking (ECC)
	// column nfFrm + 19 + iPoint * nfPnt: execution time (sec) for post-processing

	// Get arguments
//	cv::CommandLineParser parser(argc, argv, keys);
	cv::CommandLineParser * pparser = NULL;
	if (argc >= 1) {
		pparser = new cv::CommandLineParser(argc, argv, keys);
	}

	if (pparser)
		if ((*pparser).has("help") || argc <= 1) {
			(*pparser).printMessage();
			std::cout << "\nUsage: \n";
			std::cout << "For example: TrackPointsEcc -fList=fList.txt -imgPts=imgPts.xml -motType=mType.txt -tmpSize=tmpltSize.txt \n";
		}

	// define list of picture files
	if (pparser)
		fseq.setFilesByListFile((*pparser).get<string>("fList"));
	if (fseq.num_files() == 0) {
		fseq.setDirFilesByConsole(); 
		if (fseq.num_files() <= 0) {
			std::cout << "User cancelled.\n"; cout.flush(); 
			return -1;
		}
	}
	printf("There are %d files. From %s to %s.\n", fseq.num_files(), fseq.fullPathOfFile(0).c_str(),
		fseq.fullPathOfFile(fseq.num_files() - 1).c_str());
	nFrame = fseq.num_files();

	// file name of image points ('g' for gui) --> fnameImgPts 
	fnameImgPts = string(""); 
	if (pparser)
		fnameImgPts = (*pparser).get<string>("imgPts");
	if (fnameImgPts.length() <= 0) {
		std::cout << "Enter xml file of image points (vector of Point2f, generated by points picker) ('g' for gui dialog): ";
		fnameImgPts = readStringFromCin(); 
		if (fnameImgPts.length() == 1 && fnameImgPts[0] == 'g')
			fnameImgPts = uigetfile();
		if (fnameImgPts.length() == 0) {
			std::cout << "User cancelled.\n";
			return -1;
		}
	}
	// read image points
	cv::FileStorage fsImgPts(fnameImgPts, cv::FileStorage::READ);
	if (fsImgPts.isOpened() == false)
	{
		cerr << "Cannot open image point file " << fnameImgPts << endl;
		return -1;
	}
	vector<cv::Point2f> vecP2f;
	fsImgPts["VecPoint2f"] >> vecP2f;
	nPoint = (int)vecP2f.size();
	imgPoints = cv::Mat::zeros(nPoint, 2, CV_32F);
	for (int i = 0; i < nPoint; i++) {
		imgPoints.at<float>(i, 0) = vecP2f[i].x;
		imgPoints.at<float>(i, 1) = vecP2f[i].y;
	}
	printf("Image point %d: %6.1f %6.1f \n", 0, imgPoints.at<float>(0, 0), imgPoints.at<float>(0, 1));
	printf("Image point %d: %6.1f %6.1f \n", nPoint - 1, imgPoints.at<float>(nPoint - 1, 0), imgPoints.at<float>(nPoint - 1, 1));
	//	ifImgPts.close(); 
	fsImgPts.release();

	// template info (motion type, width, height, search range x, search range y)
	mTypes.resize(nPoint); 
	maxSearchSizeX.resize(nPoint); 
	maxSearchSizeY.resize(nPoint); 
	tmpltBoxes.resize(nPoint); 
	// check -tmplts
	if (pparser != NULL && pparser->has("tmplts")) {
		// read from assigned template info file (E.g., -tmplts=c:/folder/tmpltInfo.txt
		fnameTmplts = pparser->get<string>("tmplts");
	}
	ifstream ifTmplts(fnameTmplts);
	// ask user to input tmplts file
	while (ifTmplts.is_open() == false) {
		std::cout << "Enter file of template info file (each line: motType tmplt_width tmplt_height search_range_x search_range_y): ";
		fnameTmplts = readStringFromCin();
		ifTmplts.open(fnameTmplts);
		if (ifTmplts.is_open() == false) {
			std::cout << "Cannot open template info file " << fnameTmplts << endl;
			return -1;
		}		
	}
	int motType = 0;  // motion type default value
	int tmpltW = 50;  // template width default value
	int tmpltH = 50;  // template height default value
	int srchX = 50;   // search range x default value
	int srchY = 50;   // search range y default value
	int tmpInfo[5] = { motType, tmpltW, tmpltH, srchX, srchY }; // set tmpInfo to default values
	for (int i = 0; i < nPoint; i++) {
		if (ifTmplts.eof() == false) {
			string strbufLine = readStringLineFromIstream(ifTmplts); // read motType tmpltW tmpltH srchX srchY
			vector<string> strings = readStringsFromStringLine(strbufLine);
			for (int j = 0; j < 5; j++) {
				// update tmpInfo. 
				// If not updated, tmpInfo remains either default values or previous values.
				if (strings.size() >= j + 1) {
					try { // try to convert each string to integer
						tmpInfo[j] = stoi(strings[j]);
					}
					catch (...) {
						cerr << "   Warning:Cannot parse template info Point " << i << ": " << strings[j] << endl;
						continue;
					}
				}
			}
		}
		// set this point to updated value 
		// or previous value if eof 
		// or default if never set
		mTypes[i] = tmpInfo[0];
		tmpltBoxes[i].width = tmpInfo[1];
		tmpltBoxes[i].height = tmpInfo[2];
		maxSearchSizeX[i] = tmpInfo[3];
		maxSearchSizeY[i] = tmpInfo[4];
	} // end of loop of each point 
	   	  
	// file name of output frame result ('g' for gui) --> oDat 
	if (pparser)
		oDat = (*pparser).get<string>("oDat");
	else
		oDat = string("");
	if (oDat.length() <= 0) {
		std::cout << "Enter file prefix of frame result (\"XXX\" for XXX_%06d.txt', 'g' for ui file dialog.): ";
		while (true) {
			oDat = readStringFromCin(); 
			if (oDat[0] == '#') continue;
			break;
		}
		if (oDat.length() == 1 && oDat[0] == 'g')
			oDat = uiputfile();
		if (oDat.length() == 0) {
			std::cout << "User chose to skip frame result.\n";
		}
	}

	// file name of output frame picture ('g' for gui) --> oFrame 
	if (pparser)
		oFrame = (*pparser).get<string>("oFrame");
	else
		oFrame = string("");
	if (oFrame.length() <= 0) {
		std::cout << "Enter file prefix of frame picture (\"XXX\" for XXX_%06d.JPG', single-char for not outputing, 'g' for ui file dialog.): ";
		oFrame = readStringFromCin();
		if (oFrame.length() == 1 && oFrame[0] == 'g')
			oFrame = uiputfile();
		if (oFrame.length() == 0 || (oFrame.length() == 1 && oFrame[0] == 'n')) {
			std::cout << "User chose to skip frame picture.\n";
			oFrame = string("");
		}
	}

	// file name of output video ('g' for gui) --> oVideo 
	if (pparser)
		oVideo = (*pparser).get<string>("oVideo");
	else
		oVideo = string("");
	if (oVideo.length() <= 0) {
		std::cout << "Enter output video file name, single-char for not outputing, 'g' for ui file dialog.): ";
		oVideo = readStringFromCin();
		if (oVideo.length() == 1 && oVideo[0] == 'g')
			oVideo = uiputfile();
		if (oVideo.length() <= 1) {
			std::cout << "User chose to skip video output.\n";
			oVideo = string("");
		}
	}

	// file name of output summary ('g' for gui) --> oSum 
	if (pparser)
		oSum = (*pparser).get<string>("oSum");
	else
		oSum = string("");
	if (oSum.length() <= 0) {
		std::cout << "Enter file of summary result ('g' for ui file dialog.): ";
		oSum = readStringFromCin(); 
		if (oSum.length() == 1 && oSum[0] == 'g')
			oSum = uiputfile();
		if (oSum.length() == 0) {
			std::cout << "User chose to skip summary file.\n";
		}
	}

	if (pparser)
		oCpt = (*pparser).get<string>("oCpt");
	else
		oCpt = string("");
	if (oCpt.length() <= 0) {
		std::cout << "Enter file of compact summary result (only image x y for each point)  ('g' for ui file dialog.): ";
		oCpt = readStringFromCin(); 
		if (oCpt.length() == 1 && oCpt[0] == 'g')
			oCpt = uiputfile();
		if (oCpt.length() == 0) {
			std::cout << "User chose to skip summary file.\n";
		}
	}

	// show boxes of tracked points --> showBx  
	std::string showBxStr = string("");
	if (pparser)
		showBxStr = (*pparser).get<string>("showBx");
	if (showBxStr.length() <= 0) {
		std::cout << "Show pictures of tracked points? (1 for true): ";
		showBxStr = readStringFromCin();
		if (showBxStr.length() >= 1 && showBxStr[0] == '1')
			showBx = true;
		else
			showBx = false; 
	}
	
	printf("Motion type of point %d is %d \n", 0, mTypes[0]);
	printf("Motion type of point %d is %d \n", nPoint - 1, mTypes[nPoint - 1]);
	printf("Tmplt size of point %d is %d %d\n", 0, tmpltBoxes[0].width, tmpltBoxes[0].height);
	printf("Tmplt size of point %d is %d %d\n", nPoint - 1, tmpltBoxes[nPoint - 1].width, tmpltBoxes[nPoint - 1].height);

	// initialize big table  
	bigTableEcc = cv::Mat::zeros(nFrame, nfFrm + nfPnt * nPoint, CV_32F);

	// Frame 0 operations
	int iFrame = 0;
	double t_imreadFrm0 = (double)cv::getTickCount();
	imgInit = cv::imread(fseq.fullPathOfFile(iFrame), cv::IMREAD_GRAYSCALE);
	if (imgInit.cols <= 0 || imgInit.rows <= 0) {
		cerr << "Cannot read image " << iFrame << ": " << fseq.fullPathOfFile(iFrame) << ".\n";
		cerr.flush();
		return -1;
	}
	t_imreadFrm0 = ((double)cv::getTickCount() - t_imreadFrm0) / cv::getTickFrequency();
	bigTableEcc.at<float>(iFrame, 0) = (float)iFrame;
	bigTableEcc.at<float>(iFrame, 1) = (float)nPoint;
	bigTableEcc.at<float>(iFrame, 2) = (float)t_imreadFrm0; // execution time (sec) to read image file
	bigTableEcc.at<float>(iFrame, 3) = (float) 0.f; //	execution time (sec) to write frame result file 
	bigTableEcc.at<float>(iFrame, 4) = (float) 0.f; //	execution time (sec) to write frame boxed image
	for (int iPoint = 0; iPoint < nPoint; iPoint++)
	{
		cv::Point2f ref;
		tmpltBoxes[iPoint] = getTmpltRectFromImage(imgInit,
			cv::Point2f(imgPoints.at<float>(iPoint, 0), imgPoints.at<float>(iPoint, 1)),
			cv::Size(tmpltBoxes[iPoint].width, tmpltBoxes[iPoint].height),
			ref);
		bigTableEcc.at<float>(iFrame, nfFrm + 0 + iPoint * nfPnt) = (float)tmpltBoxes[iPoint].x;      // Will not change with iFrame
		bigTableEcc.at<float>(iFrame, nfFrm + 1 + iPoint * nfPnt) = (float)tmpltBoxes[iPoint].y;		 // Will not change with iFrame
		bigTableEcc.at<float>(iFrame, nfFrm + 2 + iPoint * nfPnt) = (float)tmpltBoxes[iPoint].width;	 // Will not change with iFrame
		bigTableEcc.at<float>(iFrame, nfFrm + 3 + iPoint * nfPnt) = (float)tmpltBoxes[iPoint].height; // Will not change with iFrame
		bigTableEcc.at<float>(iFrame, nfFrm + 4 + iPoint * nfPnt) = (float)mTypes[iPoint];            // Will not change with iFrame
		bigTableEcc.at<float>(iFrame, nfFrm + 5 + iPoint * nfPnt) = 1.0f;
		bigTableEcc.at<float>(iFrame, nfFrm + 6 + iPoint * nfPnt) = 0.0f;
		bigTableEcc.at<float>(iFrame, nfFrm + 7 + iPoint * nfPnt) = (float)tmpltBoxes[iPoint].x;
		bigTableEcc.at<float>(iFrame, nfFrm + 8 + iPoint * nfPnt) = 0.0f;
		bigTableEcc.at<float>(iFrame, nfFrm + 9 + iPoint * nfPnt) = 1.0f;
		bigTableEcc.at<float>(iFrame, nfFrm + 10 + iPoint * nfPnt) = (float)tmpltBoxes[iPoint].y;
		bigTableEcc.at<float>(iFrame, nfFrm + 11 + iPoint * nfPnt) = 0.0f;
		bigTableEcc.at<float>(iFrame, nfFrm + 12 + iPoint * nfPnt) = 0.0f;
		bigTableEcc.at<float>(iFrame, nfFrm + 13 + iPoint * nfPnt) = 1.0f;
		bigTableEcc.at<float>(iFrame, nfFrm + 14 + iPoint * nfPnt) = imgPoints.at<float>(iPoint, 0);
		bigTableEcc.at<float>(iFrame, nfFrm + 15 + iPoint * nfPnt) = imgPoints.at<float>(iPoint, 1);
		bigTableEcc.at<float>(iFrame, nfFrm + 16 + iPoint * nfPnt) = 0.0f;
		bigTableEcc.at<float>(iFrame, nfFrm + 17 + iPoint * nfPnt) = 0.0f;	// execution time (sec) for pre-processing
		bigTableEcc.at<float>(iFrame, nfFrm + 18 + iPoint * nfPnt) = 0.0f;	// execution time (sec) for tracking (ECC)
		bigTableEcc.at<float>(iFrame, nfFrm + 19 + iPoint * nfPnt) = 0.0f;	// execution time (sec) for post-processing
	}

	// Main loop. 
	float ecc_threshold = 0.9f;
	int64 tickCountStart = cv::getTickCount();
	for (int iFrame = 1; iFrame < nFrame; iFrame++)
	{
		// read image
		double t_imreadFrm = (double)cv::getTickCount();
		fseq.waitForFile(iFrame);
		imgBoxed = cv::imread(fseq.fullPathOfFile(iFrame), cv::IMREAD_COLOR);
		cv::cvtColor(imgBoxed, imgCurr, cv::COLOR_BGR2GRAY); 
		if (imgCurr.cols <= 0 || imgCurr.rows <= 0) {
			cerr << "Cannot read image " << iFrame << ": " << fseq.fullPathOfFile(iFrame) << ".\n";
			cerr.flush();
			return -1;
		}
		t_imreadFrm = ((double)cv::getTickCount() - t_imreadFrm) / cv::getTickFrequency();

		bigTableEcc.at<float>(iFrame, 0) = (float)iFrame;
		bigTableEcc.at<float>(iFrame, 1) = (float)nPoint;
		bigTableEcc.at<float>(iFrame, 2) = (float)t_imreadFrm0; // execution time (sec) to read image file
		bigTableEcc.at<float>(iFrame, 3) = (float) 0.f; //	execution time (sec) to write frame result file 
		bigTableEcc.at<float>(iFrame, 4) = (float) 0.f; //	execution time (sec) to write frame boxed image

// Because ECC computing time is relatively small, openMP is not helping significantly but increasing threading load.
//#pragma omp parallel for
		for (int iPoint = 0; iPoint < nPoint; iPoint++)
		{
			// timing pre-processing
			double t_point_pre = (double)cv::getTickCount();

			// template
			bigTableEcc.at<float>(iFrame, nfFrm + 0 + iPoint * nfPnt) = (float)tmpltBoxes[iPoint].x;      // Will not change with iFrame
			bigTableEcc.at<float>(iFrame, nfFrm + 1 + iPoint * nfPnt) = (float)tmpltBoxes[iPoint].y;		// Will not change with iFrame
			bigTableEcc.at<float>(iFrame, nfFrm + 2 + iPoint * nfPnt) = (float)tmpltBoxes[iPoint].width;	// Will not change with iFrame
			bigTableEcc.at<float>(iFrame, nfFrm + 3 + iPoint * nfPnt) = (float)tmpltBoxes[iPoint].height; // Will not change with iFrame

			// motion type 
			bigTableEcc.at<float>(iFrame, nfFrm + 4 + iPoint * nfPnt) = (float)mTypes[iPoint];

			// initial guess of warp
			cv::Mat warp(3, 3, CV_32F);

			// initial guess of warp is the previous warp (find closest frame that ECC coefficient > 0.9)
			int iFramePreviousValid;
			for (iFramePreviousValid = iFrame - 1; iFramePreviousValid > 0; iFramePreviousValid--) {
				if (bigTableEcc.at<float>(iFrame - 1, nfFrm + 13 + iPoint * nfPnt) >= ecc_threshold)
					break;
			}
			warp.at<float>(0, 0) = bigTableEcc.at<float>(iFramePreviousValid, nfFrm + 5 + iPoint * nfPnt);
			warp.at<float>(0, 1) = bigTableEcc.at<float>(iFramePreviousValid, nfFrm + 6 + iPoint * nfPnt);
			warp.at<float>(0, 2) = bigTableEcc.at<float>(iFramePreviousValid, nfFrm + 7 + iPoint * nfPnt);
			warp.at<float>(1, 0) = bigTableEcc.at<float>(iFramePreviousValid, nfFrm + 8 + iPoint * nfPnt);
			warp.at<float>(1, 1) = bigTableEcc.at<float>(iFramePreviousValid, nfFrm + 9 + iPoint * nfPnt);
			warp.at<float>(1, 2) = bigTableEcc.at<float>(iFramePreviousValid, nfFrm + 10 + iPoint * nfPnt);
			warp.at<float>(2, 0) = bigTableEcc.at<float>(iFramePreviousValid, nfFrm + 11 + iPoint * nfPnt);
			warp.at<float>(2, 1) = bigTableEcc.at<float>(iFramePreviousValid, nfFrm + 12 + iPoint * nfPnt);
			warp.at<float>(2, 2) = 1.0f;

			// timing pre-processing
			t_point_pre = ((double)cv::getTickCount() - t_point_pre) / cv::getTickFrequency();

			//			cv::imshow("TMPLT", imgInit(tmpltBoxes[iPoint])); 
			//			cv::waitKey(0); 
			//			cv::destroyWindow("TMPLT"); 
			//			std::cout << "Motion type: " << bigTableEcc.at<float>(iFrame, nfFrm +  4 + iPoint * nfPnt) << endl;
			//			cout.flush(); 

						// timing tracking
			double t_point_tracking = (double)cv::getTickCount();

			// ECC Tracking 
			int motion_type = (int)bigTableEcc.at<float>(iFrame, nfFrm + 4 + iPoint * nfPnt);
			double ecc_Coef;
			cv::Mat warpX3;
			if (motion_type == cv::MOTION_HOMOGRAPHY)
				warpX3 = warp(cv::Rect(0, 0, 3, 3));
			else
				warpX3 = warp(cv::Rect(0, 0, 3, 2));
			//				std::cout << "Warp before: \n" << warp << endl;
			try {
				int criteriaCount = 50;
				double eps = 0.01;
				int cloneImagesBeforeEcc = 1;
				if (cloneImagesBeforeEcc == 0) {
					ecc_Coef = cv::findTransformECC(
						imgInit(tmpltBoxes[iPoint]),
						imgCurr,
						warpX3, // warp matrix (input: initial guess, output: updated)
						motion_type,   // motion type
						cv::TermCriteria(cv::TermCriteria::COUNT + cv::TermCriteria::EPS, criteriaCount, eps));
				}
				else if (cloneImagesBeforeEcc == 1) {
					// copy to smaller clone images
					int maxMoveX = maxSearchSizeX[iPoint];
					int maxMoveY = maxSearchSizeY[iPoint];
					cv::Point2f refPoint;
					cv::Mat imgTmplt, imgSearch;
					imgInit(tmpltBoxes[iPoint]).copyTo(imgTmplt);
					cv::Rect rectSearch =
						getTmpltRectFromImage(imgCurr, cv::Point2f(warpX3.at<float>(0, 2), warpX3.at<float>(1, 2)),
							cv::Size(imgTmplt.cols + 2 * maxMoveX, imgTmplt.rows + 2 * maxMoveY), refPoint);
					imgCurr(rectSearch).copyTo(imgSearch);
					warpX3.at<float>(0, 2) -= rectSearch.x;
					warpX3.at<float>(1, 2) -= rectSearch.y;
					ecc_Coef = cv::findTransformECC(
						imgTmplt,
						imgSearch,
						warpX3, // warp matrix (input: initial guess, output: updated)
						motion_type,   // motion type
						cv::TermCriteria(cv::TermCriteria::COUNT + cv::TermCriteria::EPS, criteriaCount, eps));
					warpX3.at<float>(0, 2) += rectSearch.x;
					warpX3.at<float>(1, 2) += rectSearch.y;
				}
			}
			catch (...) {
				// If ECC fails, use previous frame result with coefficiet = 0.0f
				warp.at<float>(0, 0) = bigTableEcc.at<float>(iFrame - 1, nfFrm + 5 + iPoint * nfPnt);
				warp.at<float>(0, 1) = bigTableEcc.at<float>(iFrame - 1, nfFrm + 6 + iPoint * nfPnt);
				warp.at<float>(0, 2) = bigTableEcc.at<float>(iFrame - 1, nfFrm + 7 + iPoint * nfPnt);
				warp.at<float>(1, 0) = bigTableEcc.at<float>(iFrame - 1, nfFrm + 8 + iPoint * nfPnt);
				warp.at<float>(1, 1) = bigTableEcc.at<float>(iFrame - 1, nfFrm + 9 + iPoint * nfPnt);
				warp.at<float>(1, 2) = bigTableEcc.at<float>(iFrame - 1, nfFrm + 10 + iPoint * nfPnt);
				warp.at<float>(2, 0) = bigTableEcc.at<float>(iFrame - 1, nfFrm + 11 + iPoint * nfPnt);
				warp.at<float>(2, 1);  bigTableEcc.at<float>(iFrame - 1, nfFrm + 12 + iPoint * nfPnt);
				ecc_Coef = 0.f;
			}

			t_point_tracking = ((double)cv::getTickCount() - t_point_tracking) / cv::getTickFrequency();

			//				std::cout << "Warp after: \n" << warp << endl;
			//				cout.flush(); 
			//				system("pause"); 

						// timing post-processing
			double t_point_post = (double)cv::getTickCount();

			// Update result to big table
			bigTableEcc.at<float>(iFrame, nfFrm + 5 + iPoint * nfPnt) = warp.at<float>(0, 0);
			bigTableEcc.at<float>(iFrame, nfFrm + 6 + iPoint * nfPnt) = warp.at<float>(0, 1);
			bigTableEcc.at<float>(iFrame, nfFrm + 7 + iPoint * nfPnt) = warp.at<float>(0, 2);
			bigTableEcc.at<float>(iFrame, nfFrm + 8 + iPoint * nfPnt) = warp.at<float>(1, 0);
			bigTableEcc.at<float>(iFrame, nfFrm + 9 + iPoint * nfPnt) = warp.at<float>(1, 1);
			bigTableEcc.at<float>(iFrame, nfFrm + 10 + iPoint * nfPnt) = warp.at<float>(1, 2);
			bigTableEcc.at<float>(iFrame, nfFrm + 11 + iPoint * nfPnt) = warp.at<float>(2, 0);
			bigTableEcc.at<float>(iFrame, nfFrm + 12 + iPoint * nfPnt) = warp.at<float>(2, 1);
			bigTableEcc.at<float>(iFrame, nfFrm + 13 + iPoint * nfPnt) = (float)ecc_Coef;

			// Find current image point by warp matrix multiplication 
			cv::Mat refPoint(3, 1, CV_32F);
			refPoint.at<float>(0, 0) = imgPoints.at<float>(iPoint, 0) - (float)tmpltBoxes[iPoint].x;
			refPoint.at<float>(1, 0) = imgPoints.at<float>(iPoint, 1) - (float)tmpltBoxes[iPoint].y;
			refPoint.at<float>(2, 0) = 1.f;
			refPoint = warp * refPoint;
			bigTableEcc.at<float>(iFrame, nfFrm + 14 + iPoint * nfPnt) = refPoint.at<float>(0, 0);
			bigTableEcc.at<float>(iFrame, nfFrm + 15 + iPoint * nfPnt) = refPoint.at<float>(1, 0);

			// Find rotation by cv::Rodrigues (in degree)
			cv::Mat m33 = cv::Mat::eye(3, 3, CV_32F), rv3 = cv::Mat::zeros(3, 1, CV_32F);
			m33.at<float>(0, 0) = warp.at<float>(0, 0);
			m33.at<float>(0, 1) = warp.at<float>(0, 1);
			m33.at<float>(1, 0) = warp.at<float>(1, 0);
			m33.at<float>(1, 1) = warp.at<float>(1, 1);
			cv::Rodrigues(m33, rv3);
			bigTableEcc.at<float>(iFrame, nfFrm + 16 + iPoint * nfPnt) = rv3.at<float>(2, 0) * 180.f / 3.141592653589f;

			t_point_post = ((double)cv::getTickCount() - t_point_post) / cv::getTickFrequency();

			bigTableEcc.at<float>(iFrame, nfFrm + 17 + iPoint * nfPnt) = (float)t_point_pre;      // execution time (sec) for pre-processing 
			bigTableEcc.at<float>(iFrame, nfFrm + 18 + iPoint * nfPnt) = (float)t_point_tracking; // execution time (sec) for tracking (ECC)
			bigTableEcc.at<float>(iFrame, nfFrm + 19 + iPoint * nfPnt) = (float)t_point_post;     // execution time (sec) for post-processing

		} // next point

		// print marked boxes picture of each frame
		double t_writeImg = (double)cv::getTickCount();
		if (oFrame.length() > 0 || showBx == true || oVideo.length() > 0) {
			// plot boxes on imgBoxed
			for (int iPoint = 0; iPoint < nPoint; iPoint++) {
				// get warp matrix of iPoint of iFrame
				cv::Mat warp(3, 3, CV_32F);
				warp.at<float>(0, 0) = bigTableEcc.at<float>(iFrame, nfFrm + 5 + iPoint * nfPnt);
				warp.at<float>(0, 1) = bigTableEcc.at<float>(iFrame, nfFrm + 6 + iPoint * nfPnt);
				warp.at<float>(0, 2) = bigTableEcc.at<float>(iFrame, nfFrm + 7 + iPoint * nfPnt);
				warp.at<float>(1, 0) = bigTableEcc.at<float>(iFrame, nfFrm + 8 + iPoint * nfPnt);
				warp.at<float>(1, 1) = bigTableEcc.at<float>(iFrame, nfFrm + 9 + iPoint * nfPnt);
				warp.at<float>(1, 2) = bigTableEcc.at<float>(iFrame, nfFrm + 10 + iPoint * nfPnt);
				warp.at<float>(2, 0) = bigTableEcc.at<float>(iFrame, nfFrm + 11 + iPoint * nfPnt);
				warp.at<float>(2, 1) = bigTableEcc.at<float>(iFrame, nfFrm + 12 + iPoint * nfPnt);
				warp.at<float>(2, 2) = 1.0f;
				// define un-warp box
				cv::Mat p4m(3, 5, CV_32F);
				p4m.at<float>(0, 0) = 0.f;
				p4m.at<float>(1, 0) = 0.f;
				p4m.at<float>(2, 0) = 1.f;
				p4m.at<float>(0, 1) = 0.f;
				p4m.at<float>(1, 1) = bigTableEcc.at<float>(iFrame, nfFrm + 3 + iPoint * nfPnt); // h
				p4m.at<float>(2, 1) = 1.f;
				p4m.at<float>(0, 2) = bigTableEcc.at<float>(iFrame, nfFrm + 2 + iPoint * nfPnt); // w
				p4m.at<float>(1, 2) = bigTableEcc.at<float>(iFrame, nfFrm + 3 + iPoint * nfPnt); // h
				p4m.at<float>(2, 2) = 1.f;
				p4m.at<float>(0, 3) = bigTableEcc.at<float>(iFrame, nfFrm + 2 + iPoint * nfPnt); // w
				p4m.at<float>(1, 3) = 0.f;
				p4m.at<float>(2, 4) = imgPoints.at<float>(iPoint, 0) - (float)tmpltBoxes[iPoint].x;
				p4m.at<float>(1, 4) = imgPoints.at<float>(iPoint, 1) - (float)tmpltBoxes[iPoint].y;
				p4m.at<float>(2, 4) = 1.f;
				// calculate warpped box
				p4m = warp * p4m;
				p4m.at<float>(0, 0) /= p4m.at<float>(2, 0);
				p4m.at<float>(0, 1) /= p4m.at<float>(2, 1);
				p4m.at<float>(0, 2) /= p4m.at<float>(2, 2);
				p4m.at<float>(0, 3) /= p4m.at<float>(2, 3);
				p4m.at<float>(0, 4) /= p4m.at<float>(2, 4);
				p4m.at<float>(1, 0) /= p4m.at<float>(2, 0);
				p4m.at<float>(1, 1) /= p4m.at<float>(2, 1);
				p4m.at<float>(1, 2) /= p4m.at<float>(2, 2);
				p4m.at<float>(1, 3) /= p4m.at<float>(2, 3);
				p4m.at<float>(1, 4) /= p4m.at<float>(2, 4);
				// plot box 
				int shift = 6, shFact = 1 << shift;
				cv::Point p0 = cv::Point((int)(p4m.at<float>(0, 0) * shFact + .5), (int)(p4m.at<float>(1, 0) * shFact + .5));
				cv::Point p1 = cv::Point((int)(p4m.at<float>(0, 1) * shFact + .5), (int)(p4m.at<float>(1, 1) * shFact + .5));
				cv::Point p2 = cv::Point((int)(p4m.at<float>(0, 2) * shFact + .5), (int)(p4m.at<float>(1, 2) * shFact + .5));
				cv::Point p3 = cv::Point((int)(p4m.at<float>(0, 3) * shFact + .5), (int)(p4m.at<float>(1, 3) * shFact + .5));
				cv::Point p4 = cv::Point((int)(p4m.at<float>(0, 4) * shFact + .5), (int)(p4m.at<float>(1, 4) * shFact + .5));
				int thickness = 2;
				int linetype = cv::LINE_AA;
				if (bigTableEcc.at<float>(iFrame, nfFrm + 13 + iPoint * nfPnt) <= 0.0f)
					thickness = 1;
				cv::line(imgBoxed, p0, p1, cv::Scalar(127, 255, 127), thickness, linetype, shift);
				cv::line(imgBoxed, p1, p2, cv::Scalar(127, 255, 127), thickness, linetype, shift);
				cv::line(imgBoxed, p2, p3, cv::Scalar(127, 255, 127), thickness, linetype, shift);
				cv::line(imgBoxed, p3, p0, cv::Scalar(127, 255, 127), thickness, linetype, shift);
				if (bigTableEcc.at<float>(iFrame, nfFrm + 13 + iPoint * nfPnt) > ecc_threshold) {
					cv::line(imgBoxed, p0, p4, cv::Scalar(127, 255, 127), 1, linetype, shift);
					cv::line(imgBoxed, p1, p4, cv::Scalar(127, 255, 127), 1, linetype, shift);
					cv::line(imgBoxed, p2, p4, cv::Scalar(127, 255, 127), 1, linetype, shift);
					cv::line(imgBoxed, p3, p4, cv::Scalar(127, 255, 127), 1, linetype, shift);
				}

			} // end of point loop

			if (oFrame.length() > 1) {
				char ofsFrame[1000];
                snprintf(ofsFrame, 1000, "_%06d.jpg", iFrame);
				std::string ofsFrameStr = oFrame + std::string(ofsFrame);
				cv::imwrite(ofsFrameStr, imgBoxed);
			}
			if (oVideo.length() > 1 && iFrame <= 1) {
				int f4cc = preferredFourcc(); 
				oVideoWriter.open(oVideo, f4cc, 30.0, imgBoxed.size()); 
			}
			if (oVideo.length() > 0 && oVideo[0] != 'n' && oVideoWriter.isOpened())
				oVideoWriter << imgBoxed; 

			// show boxes 
			if (showBx == true) {
				cv::Mat imgShow;
				int maxW = 1280, maxH = 720;
				float facH = maxH * 1.0f / imgBoxed.rows;
				float facW = maxW * 1.0f / imgBoxed.cols;
				float fac = facH > facW ? facW : facH;
				cv::resize(imgBoxed, imgShow, cv::Size(0, 0), fac, fac, cv::INTER_LANCZOS4);
				cv::imshow("Tracked points", imgShow);
				cv::waitKey(1);
			}
		} // end if output box plot
		t_writeImg = ((double)cv::getTickCount() - t_writeImg) / cv::getTickFrequency();
		bigTableEcc.at<float>(iFrame, 4) = (float)t_writeImg; //	execution time (sec) to write frame boxed image

		// print result of this frame to a file
		double t_writeTxt = (double)cv::getTickCount();
		if (oDat.length() > 0) {
			char ofsFname[1000];
            snprintf(ofsFname, 1000, "_%06d.txt", iFrame);
			std::string ofsFnameStr = oDat + std::string(ofsFname);
			FILE * ofile;
			fopen_s(&ofile, ofsFnameStr.c_str(), "w");
			fprintf(ofile, "  Frame NumPts       T_ReadImg      T_WriteTxt      T_WriteImg");
			for (int iPoint = 0; iPoint < nPoint; iPoint++) {
				fprintf(ofile, " X0_%03d Y0_%03d  W_%03d  H_%03d MT_%03d         W00_%03d         W01_%03d         W02_%03d         W10_%03d         W11_%03d         W12_%03d         W20_%03d         W21_%03d         Ecf_%03d         Xcr_%03d         Ycr_%03d         Rot_%03d        Tpre_%03d      Ttrack_%03d       Tpost_%03d",
					iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint);
			}
			fprintf(ofile, "\n");
			fprintf(ofile, " %6d %6d", iFrame, nPoint);
			for (int i = 2; i < nfFrm; i++)
				fprintf(ofile, " %15.7f", bigTableEcc.at<float>(iFrame, i));
			for (int iPoint = 0; iPoint < nPoint; iPoint++) {
				for (int i = 0 + nfFrm + iPoint * nfPnt; i <= 4 + nfFrm + iPoint * nfPnt; i++)
					fprintf(ofile, " %6d", (int)(bigTableEcc.at<float>(iFrame, i) + .5f));
				for (int i = 5 + nfFrm + iPoint * nfPnt; i < nfFrm + (iPoint + 1) * nfPnt; i++)
					fprintf(ofile, " %15.7e", bigTableEcc.at<float>(iFrame, i));
			}
			fprintf(ofile, "\n");
			std::fclose(ofile);
		} // end of output frame result
		t_writeTxt = ((double)cv::getTickCount() - t_writeTxt) / cv::getTickFrequency();
		bigTableEcc.at<float>(iFrame, 3) = (float)t_writeTxt; //	execution time (sec) to write frame result file 

		if (iFrame % 10 == 0) {
			std::cout << "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
				"\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b";
			int64 tickCountFrameEnd = cv::getTickCount();
			float timePast = (float)((tickCountFrameEnd - tickCountStart) / cv::getTickFrequency());
			float timeTotalEstimated = timePast / ((iFrame + 1) * 1.0f / nFrame);
			float timeReamining = timeTotalEstimated - timePast;
			printf("Frame %06d/%06d. %6d points/sec. Time remaining: %6d sec.", iFrame, nFrame,
				(int)(nPoint * (iFrame + 1) / timePast), (int)(timeReamining + .5f));
		}
	} // next frame 

	// print result of all frames to a summary file
	if (oSum.length() > 0) {
		FILE * ofile;
		fopen_s(&ofile, oSum.c_str(), "w");
		fprintf(ofile, "  Frame NumPts       T_ReadImg      T_WriteTxt      T_WriteImg");
		for (int iPoint = 0; iPoint < nPoint; iPoint++) {
			fprintf(ofile, " X0_%03d Y0_%03d  W_%03d  H_%03d MT_%03d         W00_%03d         W01_%03d         W02_%03d         W10_%03d         W11_%03d         W12_%03d         W20_%03d         W21_%03d         Ecf_%03d         Xcr_%03d         Ycr_%03d         Rot_%03d        Tpre_%03d      Ttrack_%03d       Tpost_%03d",
				iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint);
		}
		fprintf(ofile, "\n");
		for (int iFrame = 0; iFrame < nFrame; iFrame++) {
			fprintf(ofile, " %6d %6d", iFrame, nPoint);
			for (int i = 2; i < nfFrm; i++)
				fprintf(ofile, " %15.7f", bigTableEcc.at<float>(iFrame, i));
			for (int iPoint = 0; iPoint < nPoint; iPoint++) {
				for (int i = 0 + nfFrm + iPoint * nfPnt; i <= 4 + nfFrm + iPoint * nfPnt; i++)
					fprintf(ofile, " %6d", (int)(bigTableEcc.at<float>(iFrame, i) + .5f));
				for (int i = 5 + nfFrm + iPoint * nfPnt; i < nfFrm + (iPoint + 1) * nfPnt; i++)
					fprintf(ofile, " %15.7e", bigTableEcc.at<float>(iFrame, i));
			}
			fprintf(ofile, "\n");
		}
		fclose(ofile);
		std::cout << oSum << " is written.\n"; cout.flush();
	}  // end of output summary 

	// print result of all frames to a compact summary file
	if (oCpt.length() > 0) {
		FILE * ofile;
		fopen_s(&ofile, oCpt.c_str(), "w");
		//		fprintf(ofile, "  Frame NumPts       T_ReadImg      T_WriteTxt      T_WriteImg");
		for (int iPoint = 0; iPoint < nPoint; iPoint++) {
			//			fprintf(ofile, " X0_%03d Y0_%03d  W_%03d  H_%03d MT_%03d         W00_%03d         W01_%03d         W02_%03d         W10_%03d         W11_%03d         W12_%03d         W20_%03d         W21_%03d         Ecf_%03d         Xcr_%03d         Ycr_%03d         Rot_%03d        Tpre_%03d      Ttrack_%03d       Tpost_%03d",
			//				iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint, iPoint);
			fprintf(ofile, "         Xcr_%03d         Ycr_%03d", iPoint, iPoint);
		}
		fprintf(ofile, "\n");
		for (int iFrame = 0; iFrame < nFrame; iFrame++) {
			//			fprintf(ofile, " %6d %6d", iFrame, nPoint);
			//			for (int i = 2; i < nfFrm; i++)
			//				fprintf(ofile, " %15.7f", bigTableEcc.at<float>(iFrame, i));
			for (int iPoint = 0; iPoint < nPoint; iPoint++) {
				//				for (int i = 0 + nfFrm + iPoint * nfPnt; i <= 4 + nfFrm + iPoint * nfPnt; i++)
				//					fprintf(ofile, " %6d", (int)(bigTableEcc.at<float>(iFrame, i) + .5f));
				//				for (int i = 5 + nfFrm + iPoint * nfPnt; i < nfFrm + (iPoint + 1) * nfPnt; i++)
				//					fprintf(ofile, " %15.7e", bigTableEcc.at<float>(iFrame, i));
				for (int i = 14 + nfFrm + iPoint * nfPnt; i <= 15 + nfFrm + iPoint * nfPnt; i++)
					fprintf(ofile, " %15.7e", bigTableEcc.at<float>(iFrame, i));
			}
			fprintf(ofile, "\n");
		}
		fclose(ofile);
		std::cout << oCpt << " is written.\n"; cout.flush();
	}  // end of output summary 

	cv::destroyWindow("Tracked points");
	return 0;
}
